{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporando a matriz: GENERO\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'F       ' u'M       ']\n",
      "Incorporando a matriz: RENTA\n",
      "Incorporando a matriz: EDAD\n",
      "Incorporando a matriz: NIV_EDUC\n",
      "[ 0.  1.  2.  3.  4.  5.  6.]\n",
      "Labels:  [u'        ' u'0' u'BAS     ' u'EUN     ' u'MED     ' u'TEC     '\n",
      " u'UNV     ']\n",
      "Incorporando a matriz: E_CIVIL\n",
      "[ 0.  1.  2.  3.  4.]\n",
      "Labels:  [u'0' u'CAS     ' u'SEP     ' u'SOL     ' u'VIU     ']\n",
      "Incorporando a matriz: COD_OFI\n",
      "Incorporando a matriz: COD_COM\n",
      "Incorporando a matriz: CIUDAD\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.]\n",
      "Labels:  [u'                ' u'0' u'ANCUD           ' u'ANGOL           '\n",
      " u'ANTOFAGASTA     ' u'ARICA           ' u'AYSEN           '\n",
      " u'CALAMA          ' u'CALBUCO         ' u'CALDERA         '\n",
      " u'CASABLANCA      ' u'CASTRO          ' u'CHILLAN         '\n",
      " u'CHUQUICAMATA    ' u'COLBUN          ' u'CON-CON         '\n",
      " u'CONCEPCION      ' u'COPIAPO         ' u'COQUIMBO        '\n",
      " u'CORONEL         ' u'COYHAIQUE       ' u'CURACAVI        '\n",
      " u'CURICO          ' u'DONIHUE         ' u'EL QUISCO       '\n",
      " u'EL SALVADOR     ' u'FRESIA          ' u'HIJUELAS        '\n",
      " u'HUASCO          ' u'IQUIQUE         ' u'LA CALERA       '\n",
      " u'LA CRUZ         ' u'LA SERENA       ' u'LINARES         '\n",
      " u'LLANQUIHUE      ' u'LLO-LLEO        ' u'LONCOCHE        '\n",
      " u'LOS ANDES       ' u'LOS ANGELES     ' u'LOS LAGOS       '\n",
      " u'LOS MUERMOS     ' u'LOS VILOS       ' u'MACHALI         '\n",
      " u'MELIPILLA       ' u'MOLINA          ' u'OSORNO          '\n",
      " u'OVALLE          ' u'PALENA          ' u'PANGUIPULLI     '\n",
      " u'PARRAL          ' u'PENAFLOR        ' u'PENCO           '\n",
      " u'PETORCA         ' u'PUERTO MONTT    ' u'PUERTO OCTAY    '\n",
      " u'PUERTO VARAS    ' u'PUNTA ARENAS    ' u'QUILLOTA        '\n",
      " u'QUILPUE         ' u'RANCAGUA        ' u'RENGO           '\n",
      " u'ROMERAL         ' u'SAN ANTONIO     ' u'SAN CLEMENTE    '\n",
      " u'SAN ESTEBAN     ' u'SAN FELIPE      ' u'SAN FERNANDO    '\n",
      " u'SAN PABLO       ' u'SAN PEDRO       ' u'SANTA CRUZ      '\n",
      " u'SANTA MARIA     ' u'SANTIAGO        ' u'STO DOMINGO     '\n",
      " u'TALAGANTE       ' u'TALCA           ' u'TALCAHUANO      '\n",
      " u'TEMUCO          ' u'TOCOPILLA       ' u'VALDIVIA        '\n",
      " u'VALLENAR        ' u'VALPARAISO      ' u'VILLARRICA      '\n",
      " u'VINA DEL MAR    ' u'VLLA ALEMANA    ']\n",
      "Incorporando a matriz: Crédito_1\n",
      "Incorporando a matriz: Crédito_2\n",
      "Incorporando a matriz: Crédito_3\n",
      "Couldn't fill missing values of  Crédito_3\n",
      "Incorporando a matriz: Crédito_4\n",
      "Incorporando a matriz: Monto solicitado\n",
      "Incorporando a matriz: Días de Mora\n",
      "Incorporando a matriz: Monto Deuda Promedio\n",
      "Incorporando a matriz: Número de meses inactivo\n",
      "Incorporando a matriz: numero de cuotas\n",
      "Incorporando a matriz: Aval\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'NO' u'SI']\n",
      "[ 0.  1.]\n",
      "Labels:  [u'NO PAGA' u'PAGA']\n",
      "PAGA No added\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "class Datos:\n",
    "    def __init__(self, name):\n",
    "        ## Abrir Excel con Datos\n",
    "        file_train = name\n",
    "        wb = openpyxl.load_workbook(file_train)\n",
    "        self.sheet = wb.get_sheet_by_name('Sheet1')\n",
    "        self.sheet = wb.active\n",
    "        self.rows = self.sheet.max_row - 1\n",
    "\n",
    "    def preprocess(self, train_, encoders_label):\n",
    "        # Forma matriz para contener datos\n",
    "        columns = self.sheet.max_column\n",
    "        self.data_matrix = np.zeros(shape=(self.rows, columns))\n",
    "        self.cols = columns\n",
    "        self.target = np.zeros(shape=(self.rows, 1))\n",
    "        \n",
    "        # Columnas con datos categoricos, se deben pasar a labels numericos usando un LabelEncoder y luego a OneHotEncoder\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18, 19]  ##\n",
    "        non_numerical_info = []\n",
    "        clases = []\n",
    "        clases_num_encode = []\n",
    "        self.features_names = []\n",
    "        empty_cell = self.sheet.cell(row=85, column=8).value  ## Ejemplo de celda vacia\n",
    "        \n",
    "        if train_:\n",
    "            self.Label_Encoders = []\n",
    "        else:\n",
    "            lab_counter = 0\n",
    "        \n",
    "        for i in range(self.cols):\n",
    "            j = 0 ## Contador para evitar primera fila\n",
    "            column_i = []\n",
    "            missing = []\n",
    "            \n",
    "            flag_non_numeric = False\n",
    "            flag_append = True\n",
    "            \n",
    "            default_type = type(self.sheet.cell(row=2, column=i+1).value)\n",
    "            #print default_type\n",
    "            \n",
    "            # Verificar si la columna es de datos no numericos\n",
    "            if i in non_numerical_columns:\n",
    "                flag_non_numeric = True\n",
    "\n",
    "            for cellObj in self.sheet.columns[i]:\n",
    "                if j > 0:   \n",
    "                    cond1 = not cellObj.value\n",
    "                    cond2 = cellObj.value == \"\"\n",
    "                    cond3 = type(cellObj.value) != default_type\n",
    "                    cond4 = i in [9,10,11,12,15] #Caracteristicas feas\n",
    "                    if not cond4:\n",
    "                        if cond1 or cond2 or cond3:\n",
    "                            #print [cond1, cond2, cond3]\n",
    "                            column_i.append(0)\n",
    "                            missing.append(j-1)\n",
    "                            #print \"Reemplazando \", cellObj.value\n",
    "                        else:\n",
    "                            column_i.append(cellObj.value)\n",
    "                    else:\n",
    "                        column_i.append(cellObj.value)\n",
    "                        \n",
    "\n",
    "                else:\n",
    "                    name = cellObj.value\n",
    "                    if i>0:\n",
    "                        if i != self.cols -1:\n",
    "                            self.features_names.append(name)\n",
    "                            print \"Incorporando a matriz: \" + name\n",
    "\n",
    "                j += 1\n",
    "               \n",
    "            \n",
    "            if flag_non_numeric:\n",
    "                \n",
    "                if train_:\n",
    "                    le = preprocessing.LabelEncoder()\n",
    "                    \n",
    "                    if i == 8:\n",
    "                        pseudo_column = list(column_i)\n",
    "                        pseudo_column.append(u'CORONEL         ')\n",
    "                        pseudo_column.append(u'FRESIA          ')\n",
    "                        pseudo_column.append(u'SAN ESTEBAN     ')\n",
    "                        pseudo_column.append(u'SAN PABLO       ')\n",
    "                        pseudo_column.append(u'SANTA CRUZ      ')   \n",
    "                        le.fit(pseudo_column)\n",
    "                    else:\n",
    "                        le.fit(column_i)\n",
    "                    \n",
    "                    self.Label_Encoders.append(le)\n",
    "                else:\n",
    "                    le = encoders_label[lab_counter]\n",
    "                    lab_counter += 1\n",
    "                \n",
    "                clases.append(list(le.classes_))\n",
    "\n",
    "                n_clases = len(le.classes_)\n",
    "                ordered_clases = np.linspace(0, n_clases - 1, n_clases)\n",
    "                inverse_ordered = le.inverse_transform(list(ordered_clases.astype(int)))\n",
    "                print ordered_clases\n",
    "                print \"Labels: \", str(inverse_ordered)\n",
    "\n",
    "                non_numerical_info.append(self.sheet.cell(row=1, column=i+1).value)\n",
    "\n",
    "                # Encode de datos\n",
    "                try:\n",
    "                    column_i = le.transform(column_i)\n",
    "                except:\n",
    "                    print \"Imposible de transformar \", name\n",
    "                \n",
    "                ## Reemplazo de datos por moda\n",
    "                mode = most_common(column_i.tolist())\n",
    "                for index in missing:\n",
    "                    column_i[index] = mode\n",
    "                \n",
    "\n",
    "            else:\n",
    "                ## Reemplazo de celdas vacias por el promedio\n",
    "                try:        \n",
    "                    mean = np.mean(column_i)\n",
    "                    for index in missing:\n",
    "                        column_i[index] = mean\n",
    "                except:\n",
    "                    print \"Couldn't fill missing values of \", name\n",
    "                \n",
    "                \n",
    "            if flag_append and i < self.cols - 1:\n",
    "                self.data_matrix[:,i] = column_i\n",
    "            else:\n",
    "                print name + \" No added\"          \n",
    "                \n",
    "            if i == self.cols - 1:\n",
    "                self.target = column_i\n",
    "               \n",
    "        \n",
    "    def OneHotEncoding(self):\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18]\n",
    "        examples = len(self.data_matrix[:,0])\n",
    "        categorical = []\n",
    "        \n",
    "        \n",
    "        for i in range(examples):\n",
    "            example_categorical = []\n",
    "            for index in non_numerical_columns:\n",
    "                example_categorical.append(self.data_matrix[i][index])\n",
    "            categorical.append(example_categorical)\n",
    "                \n",
    "        self.OHE = OneHotEncoder()\n",
    "        self.OHE.fit(categorical)\n",
    "        \n",
    "        #print OHE.n_values_\n",
    "        \n",
    "        len_one_hot = sum(self.OHE.n_values_)\n",
    "        \n",
    "        self.data = []\n",
    "        for i in range(examples):\n",
    "            one_hot = self.OHE.transform(categorical[i]).toarray()\n",
    "            row_data = []\n",
    "            # Add numerical info\n",
    "            for j in range(self.cols):\n",
    "                if not j in non_numerical_columns:\n",
    "                    row_data.append(self.data_matrix[i][j])\n",
    "                   \n",
    "            # Add categorical info\n",
    "            output = self.add_categorical_one_hot(row_data, one_hot)            \n",
    "            self.data.append(output)\n",
    "                        \n",
    "            \n",
    "    def OneHotEncoding2(self):\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18]\n",
    "        examples = len(self.data_matrix[:,0])\n",
    "        categorical = []\n",
    "        \n",
    "        \n",
    "        for i in range(examples):\n",
    "            example_categorical = []\n",
    "            for index in non_numerical_columns:\n",
    "                example_categorical.append(self.data_matrix[i][index])\n",
    "            categorical.append(example_categorical)\n",
    "                \n",
    "        self.OHE = OneHotEncoder()\n",
    "        self.OHE.fit(categorical)\n",
    "        \n",
    "        #print OHE.n_values_\n",
    "        hot = self.OHE.transform(categorical).toarray()\n",
    "        \n",
    "        \n",
    "        len_one_hot = sum(self.OHE.n_values_)\n",
    "        \n",
    "        self.data = []\n",
    "        for i in range(examples):\n",
    "            one_hot = hot[i]\n",
    "            row_data = []\n",
    "            # Add numerical info\n",
    "            for j in range(self.cols):\n",
    "                if not j in non_numerical_columns:\n",
    "                    row_data.append(self.data_matrix[i][j])\n",
    "                   \n",
    "            # Add categorical info\n",
    "            output = self.add_categorical_one_hot(row_data, one_hot)            \n",
    "            self.data.append(output)\n",
    "            \n",
    "        \n",
    "    def add_categorical_one_hot(self, row_data, one_hot):\n",
    "        output = row_data\n",
    "        for binario in one_hot:\n",
    "            output.append(binario)    \n",
    "        return output\n",
    "    \n",
    "    def feat_names(self):\n",
    "        return self.features_names\n",
    "    \n",
    "    def get_target(self):\n",
    "        return self.target\n",
    "    \n",
    "    def get_matrix(self):\n",
    "        return self.data_matrix\n",
    "    \n",
    "    def add_sum(self):\n",
    "        self.cols += 1\n",
    "        self.new_data_matrix = np.zeros(shape=(self.rows, self.cols))\n",
    "        self.new_data_matrix[:,0:self.cols - 1] = self.data_matrix \n",
    "        \n",
    "        for j in range(len(self.data_matrix[:,0])):\n",
    "            a = self.data_matrix[j,9] + self.data_matrix[j,10] \n",
    "            b = self.data_matrix[j,11] + self.data_matrix[j,12]\n",
    "            self.new_data_matrix[j, - 1] = (a + b)/4\n",
    "        \n",
    "        self.data_matrix = self.new_data_matrix\n",
    "        self.features_names.append(\"Suma Creditos\")\n",
    "        \n",
    "    def add_cuota_promedio(self):\n",
    "        self.cols += 1\n",
    "        self.new_data_matrix = np.zeros(shape=(self.rows, self.cols))\n",
    "        self.new_data_matrix[:,0:self.cols - 1] = self.data_matrix \n",
    "        \n",
    "        for j in range(len(self.data_matrix[:,0])):\n",
    "            a = self.data_matrix[j,13]  \n",
    "            b = self.data_matrix[j,17] \n",
    "            self.new_data_matrix[j, - 1] = a / b\n",
    "        \n",
    "        self.data_matrix = self.new_data_matrix\n",
    "        self.features_names.append(\"Cuota Promedio\")\n",
    "        \n",
    "                \n",
    "train_datos = Datos('CREDITRISK_RAW.xlsx')\n",
    "train_datos.preprocess(True, [])\n",
    "data_matrix = train_datos.get_matrix()\n",
    "train_datos.OneHotEncoding2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminar NaN values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(data_matrix)\n",
    "\n",
    "data_matrix = imp.transform(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Calculo de caracteristicas\n",
    "\n",
    "start_money_values = 9\n",
    "finish_money_values = 12\n",
    "\n",
    "\"\"\"\n",
    "for i in range(12-9):\n",
    "    for j in range(len(data_matrix[:,0])):\n",
    "        sueldo = data_matrix[j,2]\n",
    "        data_matrix[:,9+i] = data_matrix[:,9+i]/sueldo \n",
    "\"\"\"\n",
    "\n",
    "train_datos.add_sum()\n",
    "train_datos.add_cuota_promedio()\n",
    "data_matrix = train_datos.get_matrix()\n",
    "\n",
    "\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(data_matrix)\n",
    "\n",
    "data_matrix = imp.transform(data_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importances(clf, X, X_test):\n",
    "    importances = clf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    features_names = train_datos.feat_names()\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "\n",
    "        #print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        print str(f+1)+\". \"+ features_names[indices[f]] + \": \"+str(importances[indices[f]])\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X_test.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "    #plt.xticks(range(X_test.shape[1]), indices)\n",
    "    plt.xlim([-1, X_test.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS HISTOGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Graficos en base a las caracteristicas más importantes según Random Forest\n",
    "\n",
    "class Histogram:\n",
    "    \n",
    "    def __init__(self, data_matrix, target_matrix, feature_index, name):\n",
    "        self.name = name\n",
    "        self.index = feature_index\n",
    "        rows = len(target_matrix)\n",
    "        self.data = np.zeros(shape=(rows, 2))\n",
    "        \n",
    "        _columns = len(data_matrix[0,:])\n",
    "        self.data[:,0] = data_matrix[:, self.index]\n",
    "        #self.data[:,1] = data_matrix[:, _columns - 1]\n",
    "        self.data[:,1] = target_matrix\n",
    "        \n",
    "        _N_datos = len(self.data[:,0])\n",
    "        self.convert_data = np.zeros( shape = (_N_datos, 2))\n",
    "    \n",
    "        _Paga = 1;\n",
    "        _NoPaga = 0;\n",
    "\n",
    "        self.paga_hist = []\n",
    "        self.no_paga_hist = []\n",
    "\n",
    "        for i in range(_N_datos):\n",
    "            if self.data[i,1] == _Paga:\n",
    "                self.paga_hist.append( self.data[i,0])\n",
    "            else:\n",
    "                self.no_paga_hist.append( self.data[i,0])\n",
    "                \n",
    "        self.discrete = False\n",
    "\n",
    "\n",
    "    def set_bins(self, init_range, final_range, nbins):\n",
    "        self.bins = plt.linspace(init_range, final_range, nbins)\n",
    "        self.nbins = nbins\n",
    "        self.xlims = [init_range-0.5, final_range+0.5]\n",
    "        print self.bins\n",
    "        \n",
    "    def is_discrete(self, discrete):\n",
    "        init_range = 0\n",
    "        final_range = discrete+0.5 \n",
    "        nbins = discrete + 1\n",
    "        self.bins = plt.linspace(init_range, final_range, nbins)\n",
    "        self.nbins = discrete\n",
    "        self.bar_l = plt.linspace(0,discrete-1, discrete)\n",
    "        self.xlims = [-0.5, discrete+0.5]\n",
    "        self.discrete = True\n",
    "\n",
    "    def set_xlim(self, array):\n",
    "        self.xlims = array\n",
    "    \n",
    "    def hist(self):\n",
    "        _paid = self.paga_hist\n",
    "        _no_paid = self.no_paga_hist\n",
    "            \n",
    "        x = [_paid, _no_paid]\n",
    "        self.histo = plt.hist(x, self.bins)\n",
    "        plt.clf()\n",
    "\n",
    "        _to_bar_1 = self.histo[0][0]\n",
    "        _to_bar_2 = self.histo[0][1]\n",
    "\n",
    "        # Create the general blog and the \"subplots\" i.e. the bars\n",
    "        f, ax1 = plt.subplots(1, figsize=(10,5))\n",
    "\n",
    "        # Set the bar width\n",
    "        bar_width = 0.75\n",
    "        bar_width = (self.bins[self.nbins-1] - self.bins[0])/(self.nbins)\n",
    "\n",
    "        # positions of the left bar-boundaries\n",
    "        #bar_l = [(i+1)*2.5 for i in range(len(_to_bar_1))] #+ self.bins[0]\n",
    "        bar_l = [self.bins[0] + (i+1)*(self.bins[self.nbins-1] - self.bins[0])/(self.nbins) for i in range(len(_to_bar_1))]\n",
    "  \n",
    "        if (self.discrete == True):\n",
    "            bar_width = 1.0\n",
    "            bar_l = self.bar_l\n",
    "        \n",
    "        \n",
    "  \n",
    "    \n",
    "        # positions of the x-axis ticks (center of the bars as bar labels)\n",
    "        tick_pos = [i+(bar_width/2) for i in bar_l] #+ self.bins[0] \n",
    "\n",
    "        # Create a bar plot, in position bar_1\n",
    "        ax1.bar(bar_l,\n",
    "                # using the pre_score data\n",
    "                _to_bar_1,\n",
    "                # set the width\n",
    "                width=bar_width,\n",
    "                # with the label pre score\n",
    "                label='Paga',\n",
    "                # with alpha 0.5\n",
    "                alpha=0.5,\n",
    "                # with color\n",
    "                color='#808000')\n",
    "\n",
    "        # Create a bar plot, in position bar_1\n",
    "        ax1.bar(bar_l,\n",
    "                # using the mid_score data\n",
    "                _to_bar_2,\n",
    "                # set the width\n",
    "                width=bar_width,\n",
    "                # with pre_score on the bottom\n",
    "                bottom=_to_bar_1,\n",
    "                # with the label mid score\n",
    "                label='No paga',\n",
    "                # with alpha 0.5\n",
    "                alpha=0.5,\n",
    "                # with color\n",
    "                color='#4b0082')\n",
    "        \n",
    "\n",
    "        \n",
    "        # Set the label and legends\n",
    "        ax1.set_ylabel(\"Cantidad\")\n",
    "        ax1.set_xlabel(self.name)\n",
    "        ax1.set_xlim(self.xlims)\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Set a buffer around the edge\n",
    "        #plt.xlim([min(tick_pos)-bar_width, max(tick_pos)+bar_width])\n",
    "        \n",
    "class double_graph:\n",
    "    \n",
    "    def __init__(self, index_1, index_2, target_matrix):\n",
    "        self.index = index_1\n",
    "        self.index2 = index_2\n",
    "        rows = len(target_matrix)\n",
    "        self.data = np.zeros(shape=(rows, 3))\n",
    "        \n",
    "        _columns = len(data_matrix[0,:])\n",
    "        self.data[:,0] = data_matrix[:, self.index]\n",
    "        self.data[:,1] = data_matrix[:, _columns - 1]\n",
    "        self.data[:,2] = data_matrix[:, self.index2]\n",
    "        \n",
    "        _N_datos = len(self.data[:,0])\n",
    "        self.convert_data = np.zeros( shape = (_N_datos, 2))\n",
    "    \n",
    "        _Paga = 1;\n",
    "        _NoPaga = 0;\n",
    "\n",
    "        self.feature_1_paid = []\n",
    "        self.feature_2_paid = []\n",
    "        \n",
    "        self.feature_1_nopaid = []\n",
    "        self.feature_2_nopaid = []\n",
    "        \n",
    "        for i in range(_N_datos):\n",
    "            if self.data[i,1] == _Paga:\n",
    "                self.feature_1_paid.append(self.data[i,0]) \n",
    "                self.feature_2_paid.append(self.data[i,2])\n",
    "            else:\n",
    "                self.feature_1_nopaid.append(self.data[i,0])\n",
    "                self.feature_2_nopaid.append(self.data[i,2]) \n",
    "    \n",
    "    def plot(self):\n",
    "        plt.figure()\n",
    "        \n",
    "        p_1_x = self.feature_1_paid \n",
    "        p_1_y = self.feature_2_paid \n",
    "        \n",
    "        p_2_x = self.feature_1_nopaid \n",
    "        p_2_y = self.feature_2_nopaid \n",
    "        \n",
    "        p1, = plt.plot(p_1_x, p_1_y, 'o', color='b', alpha = 0.4)\n",
    "        p2, = plt.plot(p_2_x, p_2_y, 'o', color='y', alpha = 0.4) ##g^\n",
    "\n",
    "        x1 = min(p_1_x)\n",
    "        x2 = min(p_2_x)\n",
    "        x3 = min([x1,x2])\n",
    "        \n",
    "        y1 = min(p_1_y)\n",
    "        y2 = min(p_2_y)\n",
    "        y3 = min([y1, y2])\n",
    "        \n",
    "        x11 = max(p_1_x)\n",
    "        x22 = max(p_2_x)\n",
    "        x33 = max([x11,x22])\n",
    "        \n",
    "        y11 = max(p_1_y)\n",
    "        y22 = max(p_2_y)\n",
    "        y33 = max([y11, y22])\n",
    "        \n",
    "        x_ = x3 - (x33 - x3)*0.10\n",
    "        x_up = x33 + (x33 - x3)*0.10\n",
    "        y_ = y3 - (y33 - y3)*0.10\n",
    "        y_up = y33 + (y33 - y3)*0.10\n",
    "        \n",
    "        print [x_, x_up, y_, y_up]\n",
    "        \n",
    "        plt.axis([x_, x_up, y_, y_up])\n",
    "        plt.xlabel(features_names[self.index-1])\n",
    "        plt.ylabel(features_names[self.index2-1])\n",
    "\n",
    "        \n",
    "        \n",
    "        plt.legend([ p1, p2], [\"Paga\" ,\"No Paga\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICOS HISTOGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_hists = False\n",
    "\n",
    "if plot_hists:\n",
    "\n",
    "    ## EDAD ##\n",
    "    age_hist = Histogram(data_matrix, Y, 3, \"Edad\")\n",
    "    age_hist.set_bins(20,65, 45) ## DE 20 a 60 años, 20 intervalos\n",
    "    age_hist.hist()\n",
    "\n",
    "    ## RENTA ##\n",
    "    rent_hist = Histogram(data_matrix, Y,  2, \"Renta (Pesos)\")\n",
    "    rent_hist.set_bins(40000, 2e6, 20)\n",
    "    rent_hist.hist()\n",
    "\n",
    "    ## GENERO ##\n",
    "    genre_hist = Histogram(data_matrix, Y, 1, \"Genero\")\n",
    "    #rent_hist.set_bins(50000, 1e6, 10)\n",
    "    genre_hist.is_discrete(2)\n",
    "    genre_hist.hist()\n",
    "\n",
    "    ## NIVEL EDUCACIONAL ##\n",
    "    niv_ED_hist = Histogram(data_matrix,Y, 4, \"Nivel Educacional\")\n",
    "    #rent_hist.set_bins(50000, 1e6, 10)\n",
    "    niv_ED_hist.is_discrete(6)\n",
    "    niv_ED_hist.set_xlim([2.5,6.5])\n",
    "    niv_ED_hist.hist()\n",
    "\n",
    "    ## CANTIDAD DE MESES INACTIVO ##\n",
    "    cod_com_hist = Histogram(data_matrix, Y,  16, \"Cantidad de meses inactivo\")\n",
    "    #cod_com_hist.set_bins(0, 3, 3)\n",
    "    cod_com_hist.is_discrete(3)\n",
    "    cod_com_hist.hist()\n",
    "\n",
    "    ## COD_COM ##\n",
    "    cod_com_hist = Histogram(data_matrix, Y,  7, \"Codigo de Comuna\")\n",
    "    cod_com_hist.set_bins(0, 300, 300)\n",
    "    cod_com_hist.hist()\n",
    "\n",
    "    graph = double_graph(4,1, Y)\n",
    "    graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  1.035s\n",
      "Score:  0.930283224401\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "long_data_array = True\n",
    "\n",
    "if long_data_array:   \n",
    "    data_array = np.asarray(train_datos.data)\n",
    "    \n",
    "    delete_nans = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    delete_nans.fit(data_array)\n",
    "    data_array = delete_nans.transform(data_array)\n",
    "    \n",
    "    N_features = len(np.asarray(train_datos.data)[0,:]) \n",
    "    X = data_array[:,1:N_features]\n",
    "    Y = train_datos.get_target()\n",
    "else:\n",
    "    N_features = (len(data_matrix[0,:]) - 1) # Se resta ID y Label, PAGA o NO PAGA\n",
    "    X = data_matrix[:,1:N_features]\n",
    "    Y = train_datos.get_target()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.6, random_state = True)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=650, max_depth=None, bootstrap = True, n_jobs = -1)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "#importances(clf, X, X_test)\n",
    "\n",
    "\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print \"Score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931998768094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(adaboost, X, Y)\n",
    "print scores.mean()                             \n",
    "\n",
    "adaboost.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  3.707s\n",
      "0.883173496077\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, train_size=0.5, random_state = True)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',degree=3, C = 18.0, gamma = 0.06)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  4399.457s\n",
      "0.895379250218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, train_size=0.5, random_state = True)\n",
    "\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, 20), \n",
    "                   random_state=1)\n",
    "NN.fit(X_train, Y_train)\n",
    "\n",
    "pred = NN.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Evaluate(Datos):\n",
    "    \n",
    "    #def __init__(self, name):\n",
    "    #    file_train = \"COPIA.xlsx\"\n",
    "    #    wb = openpyxl.load_workbook(file_train)\n",
    "    #    self.sheet = wb.get_sheet_by_name('Sheet1')\n",
    "    #    self.sheet = wb.active\n",
    "    #    #self.sheet.cell(row=2, column=20).value = \"THIS IS SPARTA\" \n",
    "    \n",
    "    def OneHotEncoding_SCORE(self, encoder):\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18]\n",
    "        examples = len(self.data_matrix[:,0])\n",
    "        categorical = []\n",
    "        \n",
    "        \n",
    "        for i in range(examples):\n",
    "            example_categorical = []\n",
    "            for index in non_numerical_columns:\n",
    "                example_categorical.append(self.data_matrix[i][index])\n",
    "            categorical.append(example_categorical)\n",
    "                \n",
    "\n",
    "        hot = encoder.transform(categorical).toarray()\n",
    "        \n",
    "        len_one_hot = sum(encoder.n_values_)\n",
    "        \n",
    "        self.data = []\n",
    "        for i in range(examples):\n",
    "            one_hot = hot[i]\n",
    "            row_data = []\n",
    "            # Add numerical info\n",
    "            for j in range(self.cols):\n",
    "                if not j in non_numerical_columns:\n",
    "                    row_data.append(self.data_matrix[i][j])\n",
    "                   \n",
    "            # Add categorical info\n",
    "            output = self.add_categorical_one_hot(row_data, one_hot)            \n",
    "            self.data.append(output)\n",
    "\n",
    "\n",
    "    def evaluate(self, encoder, model):\n",
    "        self.OneHotEncoding_SCORE(encoder)\n",
    "        self.data_score = np.asarray(self.data)\n",
    "        model.predict(self.data_score)        \n",
    "        \n",
    "    \n",
    "    #def write_excel(self, output_file, model):\n",
    "    #    self.data_score = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporando a matriz: GENERO\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'F       ' u'M       ']\n",
      "Incorporando a matriz: RENTA\n",
      "Incorporando a matriz: EDAD\n",
      "Incorporando a matriz: NIV_EDUC\n",
      "[ 0.  1.  2.  3.  4.  5.  6.]\n",
      "Labels:  [u'        ' u'0' u'BAS     ' u'EUN     ' u'MED     ' u'TEC     '\n",
      " u'UNV     ']\n",
      "Incorporando a matriz: E_CIVIL\n",
      "[ 0.  1.  2.  3.  4.]\n",
      "Labels:  [u'0' u'CAS     ' u'SEP     ' u'SOL     ' u'VIU     ']\n",
      "Incorporando a matriz: COD_OFI\n",
      "Incorporando a matriz: COD_COM\n",
      "Incorporando a matriz: CIUDAD\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.]\n",
      "Labels:  [u'                ' u'0' u'ANCUD           ' u'ANGOL           '\n",
      " u'ANTOFAGASTA     ' u'ARICA           ' u'AYSEN           '\n",
      " u'CALAMA          ' u'CALBUCO         ' u'CALDERA         '\n",
      " u'CASABLANCA      ' u'CASTRO          ' u'CHILLAN         '\n",
      " u'CHUQUICAMATA    ' u'COLBUN          ' u'CON-CON         '\n",
      " u'CONCEPCION      ' u'COPIAPO         ' u'COQUIMBO        '\n",
      " u'CORONEL         ' u'COYHAIQUE       ' u'CURACAVI        '\n",
      " u'CURICO          ' u'DONIHUE         ' u'EL QUISCO       '\n",
      " u'EL SALVADOR     ' u'FRESIA          ' u'HIJUELAS        '\n",
      " u'HUASCO          ' u'IQUIQUE         ' u'LA CALERA       '\n",
      " u'LA CRUZ         ' u'LA SERENA       ' u'LINARES         '\n",
      " u'LLANQUIHUE      ' u'LLO-LLEO        ' u'LONCOCHE        '\n",
      " u'LOS ANDES       ' u'LOS ANGELES     ' u'LOS LAGOS       '\n",
      " u'LOS MUERMOS     ' u'LOS VILOS       ' u'MACHALI         '\n",
      " u'MELIPILLA       ' u'MOLINA          ' u'OSORNO          '\n",
      " u'OVALLE          ' u'PALENA          ' u'PANGUIPULLI     '\n",
      " u'PARRAL          ' u'PENAFLOR        ' u'PENCO           '\n",
      " u'PETORCA         ' u'PUERTO MONTT    ' u'PUERTO OCTAY    '\n",
      " u'PUERTO VARAS    ' u'PUNTA ARENAS    ' u'QUILLOTA        '\n",
      " u'QUILPUE         ' u'RANCAGUA        ' u'RENGO           '\n",
      " u'ROMERAL         ' u'SAN ANTONIO     ' u'SAN CLEMENTE    '\n",
      " u'SAN ESTEBAN     ' u'SAN FELIPE      ' u'SAN FERNANDO    '\n",
      " u'SAN PABLO       ' u'SAN PEDRO       ' u'SANTA CRUZ      '\n",
      " u'SANTA MARIA     ' u'SANTIAGO        ' u'STO DOMINGO     '\n",
      " u'TALAGANTE       ' u'TALCA           ' u'TALCAHUANO      '\n",
      " u'TEMUCO          ' u'TOCOPILLA       ' u'VALDIVIA        '\n",
      " u'VALLENAR        ' u'VALPARAISO      ' u'VILLARRICA      '\n",
      " u'VINA DEL MAR    ' u'VLLA ALEMANA    ']\n",
      "Incorporando a matriz: Crédito_1\n",
      "Incorporando a matriz: Crédito_2\n",
      "Incorporando a matriz: Crédito_3\n",
      "Couldn't fill missing values of  Crédito_3\n",
      "Incorporando a matriz: Crédito_4\n",
      "Incorporando a matriz: Monto solicitado\n",
      "Incorporando a matriz: Días de Mora\n",
      "Incorporando a matriz: Monto Deuda Promedio\n",
      "Incorporando a matriz: Número de meses inactivo\n",
      "Incorporando a matriz: numero de cuotas\n",
      "Incorporando a matriz: Aval\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'NO' u'SI']\n",
      "[ 0.  1.]\n",
      "Labels:  [u'NO PAGA' u'PAGA']\n",
      "Imposible de transformar  PAGA\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-ba9f158a2a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore_datos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData_Evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CREDITRISK_SCORE.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscore_datos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_datos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabel_Encoders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;31m#score_datos.evaluate(train_datos.OHE, modelo)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-23ff9e20672f>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, train_, encoders_label)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[1;31m## Reemplazo de datos por moda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mcolumn_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "#train_datos = Datos('CREDITRISK_SCORE.xlsx')\n",
    "#data_matrix = train_datos.get_matrix()\n",
    "#train_datos.OneHotEncoding()\n",
    "\n",
    "score_datos = Data_Evaluate('CREDITRISK_SCORE.xlsx')\n",
    "score_datos.preprocess(False,train_datos.Label_Encoders)\n",
    "#score_datos.evaluate(train_datos.OHE, modelo)\n",
    "\n",
    "modelo = NN\n",
    "#score_datos.evaluate(train_datos.OHE, modelo)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.29500000e+03,   5.00000000e+05,   4.90000000e+01,\n",
       "         8.00000000e+01,   8.10000000e+01,   0.00000000e+00,\n",
       "         1.28846000e+05,   0.00000000e+00,   1.88588000e+05,\n",
       "         1.87000000e+02,   6.25416667e+00,   0.00000000e+00,\n",
       "         1.00000000e+00,   1.90000000e+01,   0.00000000e+00,\n",
       "         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.00000000e+00,   0.00000000e+00])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_datos.data_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "print len(train_datos.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Point:\n",
    "   def __init__( self, x=0, y=0):\n",
    "      self.x = x\n",
    "      self.y = y\n",
    "    \n",
    "puntos = []    \n",
    "for i in range(5) :\n",
    "    p = Point(i, 2*i)\n",
    "    puntos.append(p)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntos[2].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains new labels: ['']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-5bad83a904f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tokyo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"paris\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nico\\Anaconda2\\lib\\site-packages\\sklearn\\preprocessing\\label.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y contains new labels: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains new labels: ['']"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\", \"santiago\"])\n",
    "\n",
    "list(le.classes_)\n",
    "\n",
    "print le.transform([\"tokyo\", \"\", \"paris\"]) \n",
    "\n",
    "list(le.inverse_transform([0, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
