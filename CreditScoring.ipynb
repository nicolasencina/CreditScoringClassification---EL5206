{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporando a matriz: GENERO\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'F       ' u'M       ']\n",
      "Incorporando a matriz: RENTA\n",
      "Incorporando a matriz: EDAD\n",
      "Incorporando a matriz: NIV_EDUC\n",
      "[ 0.  1.  2.  3.  4.  5.  6.]\n",
      "Labels:  [u'        ' u'0' u'BAS     ' u'EUN     ' u'MED     ' u'TEC     '\n",
      " u'UNV     ']\n",
      "Incorporando a matriz: E_CIVIL\n",
      "[ 0.  1.  2.  3.  4.]\n",
      "Labels:  [u'0' u'CAS     ' u'SEP     ' u'SOL     ' u'VIU     ']\n",
      "Incorporando a matriz: COD_OFI\n",
      "Incorporando a matriz: COD_COM\n",
      "Incorporando a matriz: CIUDAD\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.]\n",
      "Labels:  [u'                ' u'0' u'ANCUD           ' u'ANGOL           '\n",
      " u'ANTOFAGASTA     ' u'ARICA           ' u'AYSEN           '\n",
      " u'CALAMA          ' u'CALBUCO         ' u'CALDERA         '\n",
      " u'CASABLANCA      ' u'CASTRO          ' u'CHILLAN         '\n",
      " u'CHUQUICAMATA    ' u'COLBUN          ' u'CON-CON         '\n",
      " u'CONCEPCION      ' u'COPIAPO         ' u'COQUIMBO        '\n",
      " u'CORONEL         ' u'COYHAIQUE       ' u'CURACAVI        '\n",
      " u'CURICO          ' u'DONIHUE         ' u'EL QUISCO       '\n",
      " u'EL SALVADOR     ' u'FRESIA          ' u'HIJUELAS        '\n",
      " u'HUASCO          ' u'IQUIQUE         ' u'LA CALERA       '\n",
      " u'LA CRUZ         ' u'LA SERENA       ' u'LINARES         '\n",
      " u'LLANQUIHUE      ' u'LLO-LLEO        ' u'LONCOCHE        '\n",
      " u'LOS ANDES       ' u'LOS ANGELES     ' u'LOS LAGOS       '\n",
      " u'LOS MUERMOS     ' u'LOS VILOS       ' u'MACHALI         '\n",
      " u'MELIPILLA       ' u'MOLINA          ' u'OSORNO          '\n",
      " u'OVALLE          ' u'PALENA          ' u'PANGUIPULLI     '\n",
      " u'PARRAL          ' u'PENAFLOR        ' u'PENCO           '\n",
      " u'PETORCA         ' u'PUERTO MONTT    ' u'PUERTO OCTAY    '\n",
      " u'PUERTO VARAS    ' u'PUNTA ARENAS    ' u'QUILLOTA        '\n",
      " u'QUILPUE         ' u'RANCAGUA        ' u'RENGO           '\n",
      " u'ROMERAL         ' u'SAN ANTONIO     ' u'SAN CLEMENTE    '\n",
      " u'SAN ESTEBAN     ' u'SAN FELIPE      ' u'SAN FERNANDO    '\n",
      " u'SAN PABLO       ' u'SAN PEDRO       ' u'SANTA CRUZ      '\n",
      " u'SANTA MARIA     ' u'SANTIAGO        ' u'STO DOMINGO     '\n",
      " u'TALAGANTE       ' u'TALCA           ' u'TALCAHUANO      '\n",
      " u'TEMUCO          ' u'TOCOPILLA       ' u'VALDIVIA        '\n",
      " u'VALLENAR        ' u'VALPARAISO      ' u'VILLARRICA      '\n",
      " u'VINA DEL MAR    ' u'VLLA ALEMANA    ']\n",
      "Incorporando a matriz: Crédito_1\n",
      "Incorporando a matriz: Crédito_2\n",
      "Incorporando a matriz: Crédito_3\n",
      "Couldn't fill missing values of  Crédito_3\n",
      "Incorporando a matriz: Crédito_4\n",
      "Incorporando a matriz: Monto solicitado\n",
      "Incorporando a matriz: Días de Mora\n",
      "Incorporando a matriz: Monto Deuda Promedio\n",
      "Incorporando a matriz: Número de meses inactivo\n",
      "Incorporando a matriz: numero de cuotas\n",
      "Incorporando a matriz: Aval\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'NO' u'SI']\n",
      "[ 0.  1.]\n",
      "Labels:  [u'NO PAGA' u'PAGA']\n",
      "PAGA No added\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "class Datos:\n",
    "    def __init__(self, name):\n",
    "        ## Abrir Excel con Datos\n",
    "        file_train = name\n",
    "        wb = openpyxl.load_workbook(file_train)\n",
    "        self.sheet = wb.get_sheet_by_name('Sheet1')\n",
    "        self.sheet = wb.active\n",
    "        self.rows = self.sheet.max_row - 1\n",
    "\n",
    "    def preprocess(self, train_, encoders_label):\n",
    "        # Forma matriz para contener datos\n",
    "        columns = self.sheet.max_column\n",
    "        self.data_matrix = np.zeros(shape=(self.rows, columns))\n",
    "        self.cols = columns\n",
    "        self.target = np.zeros(shape=(self.rows, 1))\n",
    "        \n",
    "        # Columnas con datos categoricos, se deben pasar a labels numericos usando un LabelEncoder y luego a OneHotEncoder\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18, 19]  ##\n",
    "        non_numerical_info = []\n",
    "        clases = []\n",
    "        clases_num_encode = []\n",
    "        self.features_names = []\n",
    "        empty_cell = self.sheet.cell(row=85, column=8).value  ## Ejemplo de celda vacia\n",
    "        \n",
    "        if train_:\n",
    "            self.Label_Encoders = []\n",
    "        else:\n",
    "            lab_counter = 0\n",
    "        \n",
    "        for i in range(self.cols):\n",
    "            j = 0 ## Contador para evitar primera fila\n",
    "            column_i = []\n",
    "            missing = []\n",
    "            \n",
    "            flag_non_numeric = False\n",
    "            flag_append = True\n",
    "            \n",
    "            default_type = type(self.sheet.cell(row=2, column=i+1).value)\n",
    "            #print default_type\n",
    "            \n",
    "            # Verificar si la columna es de datos no numericos\n",
    "            if i in non_numerical_columns:\n",
    "                flag_non_numeric = True\n",
    "\n",
    "            for cellObj in self.sheet.columns[i]:\n",
    "                if j > 0:   \n",
    "                    cond1 = not cellObj.value\n",
    "                    cond2 = cellObj.value == \"\"\n",
    "                    cond3 = type(cellObj.value) != default_type\n",
    "                    cond4 = i in [9,10,11,12,15] #Caracteristicas feas\n",
    "                    if not cond4:\n",
    "                        if cond1 or cond2 or cond3:\n",
    "                            #print [cond1, cond2, cond3]\n",
    "                            column_i.append(0)\n",
    "                            missing.append(j-1)\n",
    "                            #print \"Reemplazando \", cellObj.value\n",
    "                        else:\n",
    "                            column_i.append(cellObj.value)\n",
    "                    else:\n",
    "                        column_i.append(cellObj.value)\n",
    "                        \n",
    "\n",
    "                else:\n",
    "                    name = cellObj.value\n",
    "                    if i>0:\n",
    "                        if i != self.cols -1:\n",
    "                            self.features_names.append(name)\n",
    "                            print \"Incorporando a matriz: \" + name\n",
    "\n",
    "                j += 1\n",
    "               \n",
    "            \n",
    "            if flag_non_numeric:\n",
    "                \n",
    "                if train_:\n",
    "                    le = preprocessing.LabelEncoder()\n",
    "                    \n",
    "                    if i == 8:\n",
    "                        pseudo_column = list(column_i)\n",
    "                        pseudo_column.append(u'CORONEL         ')\n",
    "                        pseudo_column.append(u'FRESIA          ')\n",
    "                        pseudo_column.append(u'SAN ESTEBAN     ')\n",
    "                        pseudo_column.append(u'SAN PABLO       ')\n",
    "                        pseudo_column.append(u'SANTA CRUZ      ')   \n",
    "                        le.fit(pseudo_column)\n",
    "                    else:\n",
    "                        le.fit(column_i)\n",
    "                    \n",
    "                    self.Label_Encoders.append(le)\n",
    "                else:\n",
    "                    le = encoders_label[lab_counter]\n",
    "                    lab_counter += 1\n",
    "                \n",
    "                clases.append(list(le.classes_))\n",
    "\n",
    "                n_clases = len(le.classes_)\n",
    "                ordered_clases = np.linspace(0, n_clases - 1, n_clases)\n",
    "                inverse_ordered = le.inverse_transform(list(ordered_clases.astype(int)))\n",
    "                print ordered_clases\n",
    "                print \"Labels: \", str(inverse_ordered)\n",
    "\n",
    "                non_numerical_info.append(self.sheet.cell(row=1, column=i+1).value)\n",
    "\n",
    "                # Encode de datos\n",
    "                try:\n",
    "                    column_i = le.transform(column_i)\n",
    "                    ## Reemplazo de datos por moda\n",
    "                    mode = most_common(column_i.tolist())\n",
    "                    for index in missing:\n",
    "                        column_i[index] = mode\n",
    "                        \n",
    "                except:\n",
    "                    print \"Imposible de transformar \", name\n",
    "                \n",
    "\n",
    "            else:\n",
    "                ## Reemplazo de celdas vacias por el promedio\n",
    "                try:        \n",
    "                    mean = np.mean(column_i)\n",
    "                    for index in missing:\n",
    "                        column_i[index] = mean\n",
    "                except:\n",
    "                    print \"Couldn't fill missing values of \", name\n",
    "                \n",
    "                \n",
    "            if flag_append and i < self.cols - 1:\n",
    "                self.data_matrix[:,i] = column_i\n",
    "            else:\n",
    "                print name + \" No added\"          \n",
    "                \n",
    "            if i == self.cols - 1:\n",
    "                self.target = column_i\n",
    "               \n",
    "        \n",
    "    def OneHotEncoding(self):\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18]\n",
    "        examples = len(self.data_matrix[:,0])\n",
    "        categorical = []\n",
    "        \n",
    "        \n",
    "        for i in range(examples):\n",
    "            example_categorical = []\n",
    "            for index in non_numerical_columns:\n",
    "                example_categorical.append(self.data_matrix[i][index])\n",
    "            categorical.append(example_categorical)\n",
    "                \n",
    "        self.OHE = OneHotEncoder()\n",
    "        self.OHE.fit(categorical)\n",
    "        \n",
    "        #print OHE.n_values_\n",
    "        \n",
    "        len_one_hot = sum(self.OHE.n_values_)\n",
    "        \n",
    "        self.data = []\n",
    "        for i in range(examples):\n",
    "            one_hot = self.OHE.transform(categorical[i]).toarray()\n",
    "            row_data = []\n",
    "            # Add numerical info\n",
    "            for j in range(self.cols):\n",
    "                if not j in non_numerical_columns:\n",
    "                    row_data.append(self.data_matrix[i][j])\n",
    "                   \n",
    "            # Add categorical info\n",
    "            output = self.add_categorical_one_hot(row_data, one_hot)            \n",
    "            self.data.append(output)\n",
    "                        \n",
    "            \n",
    "    def OneHotEncoding2(self):\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18]\n",
    "        examples = len(self.data_matrix[:,0])\n",
    "        categorical = []\n",
    "        \n",
    "        \n",
    "        for i in range(examples):\n",
    "            example_categorical = []\n",
    "            for index in non_numerical_columns:\n",
    "                example_categorical.append(self.data_matrix[i][index])\n",
    "            categorical.append(example_categorical)\n",
    "                \n",
    "        self.OHE = OneHotEncoder()\n",
    "        self.OHE.fit(categorical)\n",
    "        \n",
    "        #print OHE.n_values_\n",
    "        hot = self.OHE.transform(categorical).toarray()\n",
    "        \n",
    "        \n",
    "        len_one_hot = sum(self.OHE.n_values_)\n",
    "        \n",
    "        self.data = []\n",
    "        for i in range(examples):\n",
    "            one_hot = hot[i]\n",
    "            row_data = []\n",
    "            # Add numerical info\n",
    "            for j in range(self.cols):\n",
    "                if not j in non_numerical_columns:\n",
    "                    row_data.append(self.data_matrix[i][j])\n",
    "                   \n",
    "            # Add categorical info\n",
    "            output = self.add_categorical_one_hot(row_data, one_hot)            \n",
    "            self.data.append(output)\n",
    "            \n",
    "        \n",
    "    def add_categorical_one_hot(self, row_data, one_hot):\n",
    "        output = row_data\n",
    "        for binario in one_hot:\n",
    "            output.append(binario)    \n",
    "        return output\n",
    "    \n",
    "    def feat_names(self):\n",
    "        return self.features_names\n",
    "    \n",
    "    def get_target(self):\n",
    "        return self.target\n",
    "    \n",
    "    def get_matrix(self):\n",
    "        return self.data_matrix\n",
    "    \n",
    "    def add_sum(self):\n",
    "        self.cols += 1\n",
    "        self.new_data_matrix = np.zeros(shape=(self.rows, self.cols))\n",
    "        self.new_data_matrix[:,0:self.cols - 1] = self.data_matrix \n",
    "        \n",
    "        for j in range(len(self.data_matrix[:,0])):\n",
    "            a = self.data_matrix[j,9] + self.data_matrix[j,10] \n",
    "            b = self.data_matrix[j,11] + self.data_matrix[j,12]\n",
    "            self.new_data_matrix[j, - 1] = (a + b)/4\n",
    "        \n",
    "        self.data_matrix = self.new_data_matrix\n",
    "        self.features_names.append(\"Suma Creditos\")\n",
    "        \n",
    "    def add_cuota_promedio(self):\n",
    "        self.cols += 1\n",
    "        self.new_data_matrix = np.zeros(shape=(self.rows, self.cols))\n",
    "        self.new_data_matrix[:,0:self.cols - 1] = self.data_matrix \n",
    "        \n",
    "        for j in range(len(self.data_matrix[:,0])):\n",
    "            a = self.data_matrix[j,13]  \n",
    "            b = self.data_matrix[j,17] \n",
    "            self.new_data_matrix[j, - 1] = a / b\n",
    "        \n",
    "        self.data_matrix = self.new_data_matrix\n",
    "        self.features_names.append(\"Cuota Promedio\")\n",
    "        \n",
    "                \n",
    "train_datos = Datos('CREDITRISK_RAW.xlsx')\n",
    "train_datos.preprocess(True, [])\n",
    "data_matrix = train_datos.get_matrix()\n",
    "train_datos.OneHotEncoding2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminar NaN values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(data_matrix)\n",
    "\n",
    "data_matrix = imp.transform(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Calculo de caracteristicas\n",
    "\n",
    "start_money_values = 9\n",
    "finish_money_values = 12\n",
    "\n",
    "\"\"\"\n",
    "for i in range(12-9):\n",
    "    for j in range(len(data_matrix[:,0])):\n",
    "        sueldo = data_matrix[j,2]\n",
    "        data_matrix[:,9+i] = data_matrix[:,9+i]/sueldo \n",
    "\"\"\"\n",
    "\n",
    "train_datos.add_sum()\n",
    "train_datos.add_cuota_promedio()\n",
    "data_matrix = train_datos.get_matrix()\n",
    "\n",
    "\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(data_matrix)\n",
    "\n",
    "data_matrix = imp.transform(data_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importances(clf, X, X_test):\n",
    "    importances = clf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    features_names = train_datos.feat_names()\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "\n",
    "        #print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        print str(f+1)+\". \"+ features_names[indices[f]] + \": \"+str(importances[indices[f]])\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X_test.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "    #plt.xticks(range(X_test.shape[1]), indices)\n",
    "    plt.xlim([-1, X_test.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS HISTOGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Graficos en base a las caracteristicas más importantes según Random Forest\n",
    "\n",
    "class Histogram:\n",
    "    \n",
    "    def __init__(self, data_matrix, target_matrix, feature_index, name):\n",
    "        self.name = name\n",
    "        self.index = feature_index\n",
    "        rows = len(target_matrix)\n",
    "        self.data = np.zeros(shape=(rows, 2))\n",
    "        \n",
    "        _columns = len(data_matrix[0,:])\n",
    "        self.data[:,0] = data_matrix[:, self.index]\n",
    "        #self.data[:,1] = data_matrix[:, _columns - 1]\n",
    "        self.data[:,1] = target_matrix\n",
    "        \n",
    "        _N_datos = len(self.data[:,0])\n",
    "        self.convert_data = np.zeros( shape = (_N_datos, 2))\n",
    "    \n",
    "        _Paga = 1;\n",
    "        _NoPaga = 0;\n",
    "\n",
    "        self.paga_hist = []\n",
    "        self.no_paga_hist = []\n",
    "\n",
    "        for i in range(_N_datos):\n",
    "            if self.data[i,1] == _Paga:\n",
    "                self.paga_hist.append( self.data[i,0])\n",
    "            else:\n",
    "                self.no_paga_hist.append( self.data[i,0])\n",
    "                \n",
    "        self.discrete = False\n",
    "\n",
    "\n",
    "    def set_bins(self, init_range, final_range, nbins):\n",
    "        self.bins = plt.linspace(init_range, final_range, nbins)\n",
    "        self.nbins = nbins\n",
    "        self.xlims = [init_range-0.5, final_range+0.5]\n",
    "        print self.bins\n",
    "        \n",
    "    def is_discrete(self, discrete):\n",
    "        init_range = 0\n",
    "        final_range = discrete+0.5 \n",
    "        nbins = discrete + 1\n",
    "        self.bins = plt.linspace(init_range, final_range, nbins)\n",
    "        self.nbins = discrete\n",
    "        self.bar_l = plt.linspace(0,discrete-1, discrete)\n",
    "        self.xlims = [-0.5, discrete+0.5]\n",
    "        self.discrete = True\n",
    "\n",
    "    def set_xlim(self, array):\n",
    "        self.xlims = array\n",
    "    \n",
    "    def hist(self):\n",
    "        _paid = self.paga_hist\n",
    "        _no_paid = self.no_paga_hist\n",
    "            \n",
    "        x = [_paid, _no_paid]\n",
    "        self.histo = plt.hist(x, self.bins)\n",
    "        plt.clf()\n",
    "\n",
    "        _to_bar_1 = self.histo[0][0]\n",
    "        _to_bar_2 = self.histo[0][1]\n",
    "\n",
    "        # Create the general blog and the \"subplots\" i.e. the bars\n",
    "        f, ax1 = plt.subplots(1, figsize=(10,5))\n",
    "\n",
    "        # Set the bar width\n",
    "        bar_width = 0.75\n",
    "        bar_width = (self.bins[self.nbins-1] - self.bins[0])/(self.nbins)\n",
    "\n",
    "        # positions of the left bar-boundaries\n",
    "        #bar_l = [(i+1)*2.5 for i in range(len(_to_bar_1))] #+ self.bins[0]\n",
    "        bar_l = [self.bins[0] + (i+1)*(self.bins[self.nbins-1] - self.bins[0])/(self.nbins) for i in range(len(_to_bar_1))]\n",
    "  \n",
    "        if (self.discrete == True):\n",
    "            bar_width = 1.0\n",
    "            bar_l = self.bar_l\n",
    "        \n",
    "        \n",
    "  \n",
    "    \n",
    "        # positions of the x-axis ticks (center of the bars as bar labels)\n",
    "        tick_pos = [i+(bar_width/2) for i in bar_l] #+ self.bins[0] \n",
    "\n",
    "        # Create a bar plot, in position bar_1\n",
    "        ax1.bar(bar_l,\n",
    "                # using the pre_score data\n",
    "                _to_bar_1,\n",
    "                # set the width\n",
    "                width=bar_width,\n",
    "                # with the label pre score\n",
    "                label='Paga',\n",
    "                # with alpha 0.5\n",
    "                alpha=0.5,\n",
    "                # with color\n",
    "                color='#808000')\n",
    "\n",
    "        # Create a bar plot, in position bar_1\n",
    "        ax1.bar(bar_l,\n",
    "                # using the mid_score data\n",
    "                _to_bar_2,\n",
    "                # set the width\n",
    "                width=bar_width,\n",
    "                # with pre_score on the bottom\n",
    "                bottom=_to_bar_1,\n",
    "                # with the label mid score\n",
    "                label='No paga',\n",
    "                # with alpha 0.5\n",
    "                alpha=0.5,\n",
    "                # with color\n",
    "                color='#4b0082')\n",
    "        \n",
    "\n",
    "        \n",
    "        # Set the label and legends\n",
    "        ax1.set_ylabel(\"Cantidad\")\n",
    "        ax1.set_xlabel(self.name)\n",
    "        ax1.set_xlim(self.xlims)\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Set a buffer around the edge\n",
    "        #plt.xlim([min(tick_pos)-bar_width, max(tick_pos)+bar_width])\n",
    "        \n",
    "class double_graph:\n",
    "    \n",
    "    def __init__(self, index_1, index_2, target_matrix):\n",
    "        self.index = index_1\n",
    "        self.index2 = index_2\n",
    "        rows = len(target_matrix)\n",
    "        self.data = np.zeros(shape=(rows, 3))\n",
    "        \n",
    "        _columns = len(data_matrix[0,:])\n",
    "        self.data[:,0] = data_matrix[:, self.index]\n",
    "        self.data[:,1] = data_matrix[:, _columns - 1]\n",
    "        self.data[:,2] = data_matrix[:, self.index2]\n",
    "        \n",
    "        _N_datos = len(self.data[:,0])\n",
    "        self.convert_data = np.zeros( shape = (_N_datos, 2))\n",
    "    \n",
    "        _Paga = 1;\n",
    "        _NoPaga = 0;\n",
    "\n",
    "        self.feature_1_paid = []\n",
    "        self.feature_2_paid = []\n",
    "        \n",
    "        self.feature_1_nopaid = []\n",
    "        self.feature_2_nopaid = []\n",
    "        \n",
    "        for i in range(_N_datos):\n",
    "            if self.data[i,1] == _Paga:\n",
    "                self.feature_1_paid.append(self.data[i,0]) \n",
    "                self.feature_2_paid.append(self.data[i,2])\n",
    "            else:\n",
    "                self.feature_1_nopaid.append(self.data[i,0])\n",
    "                self.feature_2_nopaid.append(self.data[i,2]) \n",
    "    \n",
    "    def plot(self):\n",
    "        plt.figure()\n",
    "        \n",
    "        p_1_x = self.feature_1_paid \n",
    "        p_1_y = self.feature_2_paid \n",
    "        \n",
    "        p_2_x = self.feature_1_nopaid \n",
    "        p_2_y = self.feature_2_nopaid \n",
    "        \n",
    "        p1, = plt.plot(p_1_x, p_1_y, 'o', color='b', alpha = 0.4)\n",
    "        p2, = plt.plot(p_2_x, p_2_y, 'o', color='y', alpha = 0.4) ##g^\n",
    "\n",
    "        x1 = min(p_1_x)\n",
    "        x2 = min(p_2_x)\n",
    "        x3 = min([x1,x2])\n",
    "        \n",
    "        y1 = min(p_1_y)\n",
    "        y2 = min(p_2_y)\n",
    "        y3 = min([y1, y2])\n",
    "        \n",
    "        x11 = max(p_1_x)\n",
    "        x22 = max(p_2_x)\n",
    "        x33 = max([x11,x22])\n",
    "        \n",
    "        y11 = max(p_1_y)\n",
    "        y22 = max(p_2_y)\n",
    "        y33 = max([y11, y22])\n",
    "        \n",
    "        x_ = x3 - (x33 - x3)*0.10\n",
    "        x_up = x33 + (x33 - x3)*0.10\n",
    "        y_ = y3 - (y33 - y3)*0.10\n",
    "        y_up = y33 + (y33 - y3)*0.10\n",
    "        \n",
    "        print [x_, x_up, y_, y_up]\n",
    "        \n",
    "        plt.axis([x_, x_up, y_, y_up])\n",
    "        plt.xlabel(features_names[self.index-1])\n",
    "        plt.ylabel(features_names[self.index2-1])\n",
    "\n",
    "        \n",
    "        \n",
    "        plt.legend([ p1, p2], [\"Paga\" ,\"No Paga\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICOS HISTOGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_hists = False\n",
    "\n",
    "if plot_hists:\n",
    "\n",
    "    ## EDAD ##\n",
    "    age_hist = Histogram(data_matrix, Y, 3, \"Edad\")\n",
    "    age_hist.set_bins(20,65, 45) ## DE 20 a 60 años, 20 intervalos\n",
    "    age_hist.hist()\n",
    "\n",
    "    ## RENTA ##\n",
    "    rent_hist = Histogram(data_matrix, Y,  2, \"Renta (Pesos)\")\n",
    "    rent_hist.set_bins(40000, 2e6, 20)\n",
    "    rent_hist.hist()\n",
    "\n",
    "    ## GENERO ##\n",
    "    genre_hist = Histogram(data_matrix, Y, 1, \"Genero\")\n",
    "    #rent_hist.set_bins(50000, 1e6, 10)\n",
    "    genre_hist.is_discrete(2)\n",
    "    genre_hist.hist()\n",
    "\n",
    "    ## NIVEL EDUCACIONAL ##\n",
    "    niv_ED_hist = Histogram(data_matrix,Y, 4, \"Nivel Educacional\")\n",
    "    #rent_hist.set_bins(50000, 1e6, 10)\n",
    "    niv_ED_hist.is_discrete(6)\n",
    "    niv_ED_hist.set_xlim([2.5,6.5])\n",
    "    niv_ED_hist.hist()\n",
    "\n",
    "    ## CANTIDAD DE MESES INACTIVO ##\n",
    "    cod_com_hist = Histogram(data_matrix, Y,  16, \"Cantidad de meses inactivo\")\n",
    "    #cod_com_hist.set_bins(0, 3, 3)\n",
    "    cod_com_hist.is_discrete(3)\n",
    "    cod_com_hist.hist()\n",
    "\n",
    "    ## COD_COM ##\n",
    "    cod_com_hist = Histogram(data_matrix, Y,  7, \"Codigo de Comuna\")\n",
    "    cod_com_hist.set_bins(0, 300, 300)\n",
    "    cod_com_hist.hist()\n",
    "\n",
    "    graph = double_graph(4,1, Y)\n",
    "    graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.638s\n",
      "Score:  0.93137254902\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "long_data_array = True\n",
    "\n",
    "if long_data_array:   \n",
    "    data_array = np.asarray(train_datos.data)\n",
    "    \n",
    "    delete_nans = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    delete_nans.fit(data_array)\n",
    "    data_array = delete_nans.transform(data_array)\n",
    "    \n",
    "    N_features = len(np.asarray(train_datos.data)[0,:]) \n",
    "    X = data_array[:,1:N_features]\n",
    "    Y = train_datos.get_target()\n",
    "    \n",
    "else:\n",
    "    N_features = (len(data_matrix[0,:]) - 1) # Se resta ID y Label, PAGA o NO PAGA\n",
    "    X = data_matrix[:,1:N_features]\n",
    "    Y = train_datos.get_target()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.6, random_state = True)\n",
    "\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=500, max_depth=None, bootstrap = True, n_jobs = -1)\n",
    "RF.fit(X_train, Y_train)\n",
    "Y_pred = RF.predict_proba(X_test)\n",
    "\n",
    "\n",
    "#importances(clf, X, X_test)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "t0 = time()\n",
    "pred = RF.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print \"Score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931998768094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(adaboost, X, Y)\n",
    "print scores.mean()                             \n",
    "\n",
    "adaboost.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  2764.879s\n",
      "0.895424836601\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, train_size=0.6, random_state = True)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',degree=3, C = 18.0, gamma = 0.06)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  3.547s\n",
      "0.895379250218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, train_size=0.5, random_state = True)\n",
    "\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(70, 20), \n",
    "                   random_state=1)\n",
    "NN.fit(X_train, Y_train)\n",
    "\n",
    "pred = NN.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE SENSIBILIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46949891  0.82026144  0.86492375  0.89542484  0.89433551  0.88997821]\n",
      " [ 0.46949891  0.82026144  0.86492375  0.89542484  0.89433551  0.88997821]\n",
      " [ 0.46949891  0.82026144  0.86492375  0.89542484  0.89433551  0.88997821]]\n",
      "[[0.001, 0.01, 0.1, 1, 10, 100], [0.46949891067538124, 0.82026143790849682, 0.8649237472766883, 0.89542483660130723, 0.89433551198257077, 0.8899782135076254]]\n"
     ]
    }
   ],
   "source": [
    "def iterator(iterations):\n",
    "    scores_ = []\n",
    "    parameters = []\n",
    "    for i in range(iterations):\n",
    "        parameter = (10**(i-3))\n",
    "        parameters.append(parameter)\n",
    "        model = svm.SVC(kernel='rbf',degree=3, C = parameter, gamma = 0.06)\n",
    "        model.fit(X_train, Y_train)\n",
    "        #Y_pred = model.predict_proba(X_test)\n",
    "        pred = model.predict(X_test) \n",
    "        score = metrics.accuracy_score(Y_test, pred)\n",
    "        scores_.append(score)\n",
    "    \n",
    "    return [scores_, parameters]\n",
    "\n",
    "        \n",
    "def promediador(n_models, iterations):\n",
    "    means = []\n",
    "    for i in range(n_models):\n",
    "        [score_list, parameters] = iterator(iterations)\n",
    "        means.append(score_list)\n",
    "    \n",
    "    \n",
    "    new_means = np.asarray(means)\n",
    "    print new_means\n",
    "    output_means = []\n",
    "    for i in range(iterations):\n",
    "        output_means.append(np.mean(new_means[:,i]))\n",
    "    return [parameters, output_means]\n",
    "        \n",
    "parametric_score = promediador(3, 6)\n",
    "\n",
    "print parametric_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xc04a9e8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAF5CAYAAADZMYNPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X+YXVV97/H3d2AU0WmoUkEwbYL4I/pUJRFsBNSWH4m1\nAW2u4lSLxZ8oMd4A1XoBQYXiRX4YNVRKvURucSq9qA1VCAJq25AEnYhaHdTWYKVoBKxxDFBH5nv/\n2CfmMM6EOcOss8+ceb+eZx446+y1z3d2ZuZ8zlpr7x2ZiSRJUgk9dRcgSZK6l0FDkiQVY9CQJEnF\nGDQkSVIxBg1JklSMQUOSJBVj0JAkScUYNCRJUjEGDUmSVIxBQ5IkFdMxQSMiTomIrRFxf0RsiohD\nJ7H9tyLivogYiog/bVetkiRpcjoiaETECcBFwNnAIcDXgPURse8E278FOA94N/BM4BxgTUS8tC0F\nS5KkSYlOuKlaRGwCNmfm2xuPA/gB8KHMvGCc7TcA/5KZ72xquxA4LDNf2KayJUnSw6h9RCMieoFF\nwE0727JKPzcCiyfo9mjggTFtDwCHRcQeJeqUJEmtqz1oAPsCewDbxrRvA/afoM964A0RsRAgIp4H\nvB7obexPkiR1gD3rLmCK3gfsB2yMiB7gR8Ba4B3A6HgdIuIJwBLgDn59NESSJE1sL2AesD4z722l\nYycEjXuAB6mCQ7P9qALEr8nMB6hGNN7c2O6HwJuB4cy8e4LXWQJcNS0VS5I0O70a+EQrHWoPGpk5\nEhGDwFHAOvjVYtCjgA89TN8HgbsafV4FXLubze8A+Nu//VsWLFjwyAufwVatWsUll1xSdxm18zjs\nMluPxQUXfJSrr342mS9otKwCquMQsYETTvhX/vzP31xbfXWa6Gfi14/ZLt14zKb7dyMzqd7iZpah\noSFe85rXQOO9tBW1B42Gi4G1jcBxK9Vv+95U0yFExPnAAZn52sbjpwKHAZuBxwOnAs8CTtzNazwA\nsGDBAhYuXFjmu5gh5syZM+uPAXgcms3WY7F58/fIvAzY+Yd/DlAdh8xD2LTp2Fl5XGDin4lfP2a7\ndOMxm47fjeHhYc4440KuvXYDIyOPpbd3B8uWHc55551OX1/fNFXaNi0vPeiIoJGZVzeumfFeqqmQ\n24AlTdMg+wNzm7rsAZwGPA0YAb4AvCAz/6N9VUuayTKTkZHHMt4bZiUYGdl7xn4CLcFj1rrh4WEW\nL17O0NCpjI6eQ3XskjVr1nPzzcvZuPGamRg2WtIRQQMgMy8FLp3guZPGPL6dnR87JGkKIoLe3h1A\nMv4bZ9Lbu8M3zCYes9adccaFjZCxtKk1GB1dytBQcuaZF7F69Tl1ldcWnXB6qyTVYtmyw+npWT/u\ncz0913PccUe0uaLO5zFrzbXXbmB0dMm4z42OLmXdug1trqj9DBqzUH9/f90ldASPwy6z9Vicd97p\nLFhwMT0911F9Su8Hkp6e61iw4BLOPfe0miusz0Q/E79+zKCbj9kj+d1oZaqpm3XEJcjboXFxr8HB\nwcGuWqgk6ZEZHh7mzDMvYt26DYyM7E1v730cd9zhnHvuaV0/dz5VHrPJmz//aO644/NMNNU0b94x\nbN16Y7vLatmWLVtYtGgRwKLM3NJK345ZoyFJdejr62P16nNYvXrmnnrYbh6zyVu27HDWrFk/Zo1G\nZbZMNTl1IkkNvmG2zmO2e7Ntqmk8Bg1Jkgrp6+tj48ZrWLFiM/PmHcuBBx7PvHnHsmLF5llxais4\ndSJJUlGzfarJEQ1JktpktoUMMGhIkqSCDBqSJKkYg4YkSSrGoCFJkooxaEiSpGIMGpIkqRiDhtTF\nZsu9jCR1LoOG1GWGh4dZufJs5s8/mrlzX8b8+UezcuXZDA8P112apFnIK4NKXWR4eJjFi5czNHQq\no6PnUN0xMlmzZj0337x81lzyWFLncERD6iJnnHFhI2QsZddtqYPR0aUMDa3izDMvqrM8SbOQQUPq\nItdeu4HR0SXjPjc6upR16za0uSJJs51BQ+oSmcnIyGPZNZIxVjAysrcLRCW1lUFD6hIRQW/vDmCi\nIJH09u6YlTd1klQfg4bURZYtO5yenvXjPtfTcz3HHXdEmyuSNNsZNKQuct55p7NgwcX09FzHrpGN\npKfnOhYsuIRzzz2tzvIkzUIGDamL9PX1sXHjNaxYsZl5847lwAOPZ968Y1mxYrOntkqqhdfRkLpM\nX18fq1efw+rV1QJR12RIqpMjGlIXM2RIqptBQ5IkFWPQkCRJxRg0JElSMQYNSZJUjEFDkiQVY9CQ\nJEnFGDQkSVIxBg1JklSMQUOSJBVj0JAkScUYNCRJUjEGDUmSVIxBQ5IkFWPQkCRJxRg0JElSMQYN\nSZJUjEFDkiQVY9CQJEnFGDQ0Y2Rm3SVIklpk0FBHGx4eZuXKs5k//2jmzn0Z8+cfzcqVZzM8PFx3\naZKkSdiz7gKkiQwPD7N48XKGhk5ldPQcIIBkzZr13HzzcjZuvIa+vr6aq5Qk7Y4jGupYZ5xxYSNk\nLKUKGQDB6OhShoZWceaZF9VZniRpEgwa6ljXXruB0dEl4z43OrqUdes2tLkiSVKrDBrqSJnJyMhj\n2TWSMVYwMrK3C0QlqcMZNNSRIoLe3h3AREEi6e3dQcREQUSS1AkMGupYy5YdTk/P+nGf6+m5nuOO\nO6LNFUmSWmXQUMc677zTWbDgYnp6rmPXyEbS03MdCxZcwrnnnlZneZKkSTBoqGP19fWxceM1rFix\nmXnzjuXAA49n3rxjWbFis6e2StIM4XU01NH6+vpYvfocVq+uFoi6JkOSZhZHNDRjGDIkaeYxaEiS\npGIMGpIkqZiOCRoRcUpEbI2I+yNiU0Qc+jDbvzoibouIHRFxV0R8LCIe3656JUnSw+uIoBERJwAX\nAWcDhwBfA9ZHxL4TbH848HHgcuCZwP8ADgP+ui0FS5KkSemIoAGsAi7LzCsz83bgZOA+4HUTbP97\nwNbMXJOZ38/MW4DLqMKGJEnqELUHjYjoBRYBN+1sy+oGFjcCiyfothGYGxEvaexjP+AVwGfLVitJ\nklpRe9AA9gX2ALaNad8G7D9eh8YIxmuAT0bEL4AfAv8FrChYpyRJatGMvGBXRDwTWA2cA9wAPAm4\nkGr65A2767tq1SrmzJnzkLb+/n76+/uL1CpJ0kwyMDDAwMDAQ9q2b98+5f1F3bfZbkyd3Acsz8x1\nTe1rgTmZ+fJx+lwJ7JWZr2xqOxz4Z+BJmTl2dISIWAgMDg4OsnDhwun/RiRJ6lJbtmxh0aJFAIsy\nc0srfWufOsnMEWAQOGpnW1SXgDwKuGWCbnsDvxzTNkp15y0vHylJUoeoPWg0XAy8MSJOjIhnAB+l\nChNrASLi/Ij4eNP21wLLI+LkiJjfGM1YDWzOzB+1uXZJkjSBjlijkZlXN66Z8V5gP+A2YElm3t3Y\nZH9gbtP2H4+IxwGnUK3N+CnVWSt/0dbCJUnSbnVE0ADIzEuBSyd47qRx2tYAa0rXJUmSpq5Tpk4k\nSVIXMmhIkqRiDBqSJKkYg4YkSSrGoCFJkooxaEiSpGIMGpIkqRiDhiRJKsagIUmSijFoSJKkYgwa\nkiSpGIOGJEkqxqAhSZKKMWhIkqRiDBqSJKkYg4YkSSrGoCFJkooxaEiSpGIMGpIkqRiDhiRJKsag\nIUmSijFoSJKkYgwakiSpGIOGJEkqxqAhSZKKMWhIkqRiDBqSJKkYg4YkSSrGoCFJkooxaEiSpGIM\nGpIkqRiDhiRJKsagIUmSijFoSJKkYgwakiSpGIOGJEkqxqAhSZKKMWhIkqRiDBqSJKkYg4YkSSrG\noCFJkooxaEiSpGIMGpIkqRiDhiRJKsagIUmSijFoSJKkYgwakiSpGIOGJEkqxqAhSZKK2XMyG0XE\nyins+4rMHJ5CP0mS1CUmFTSADwJ3Ag9Ocvu5wD8CBg1JkmaxyQYNgOdl5o8ns2FEGDAkSdKk12i8\nB/h5C/v9S+AnrZcjSZK6yaRGNDLzPa3sNDPPn1o5kiSpm7QydfJrImJf4PnAHsCXM/OH01KVJEnq\nClMOGhGxHPgY8B2gF3h6RJySmVdMV3GSJGlmm/R1NCLicWOazgYOy8zDMvMQ4BXAedNZnCRJmtla\nuWDXYEQc3/T4l8ATmx7vB/xiWqqSJEldoZWgsQR4U0R8OiIOAN4OfDIifhQR9wDvB9461UIi4pSI\n2BoR90fEpog4dDfbXhERoxHxYOO/O7++MdXXlyRJ02/SQSMz78jMlwJXA18CngscDBwDHA38dmZ+\nbipFRMQJwEVU0zGHAF8D1jcWm45nJbA/8KTGf59MdTrt1VN5fUmSVEbL9zrJzAHgUOA5wBeBnsy8\nLTMfeAR1rAIuy8wrM/N24GTgPuB1E9QwnJk/3vkFHAbsA6x9BDVIkqRp1lLQiIg/jIjTqK4S+gbg\nHcBVEfGBiHjMVAqIiF5gEXDTzrbMTOBGYPEkd/M64MbM/MFUapAkSWW0ctbJRcAVVKMZl0XEWZn5\nJWAh8ADw1Yh4yRRq2JfqOhzbxrRvo5oWebi6ngS8BLh8Cq8tSZIKauU6Gn8GHJuZgxHxeGAT8L7M\n/AVwVkQMAJcB101/mQ9b138B/zCZjVetWsWcOXMe0tbf309/f//0VyZJ0gwzMDDAwMDAQ9q2b98+\n5f21EjR2APOBQaq7sz5kTUZmfgs4cgo13EN1V9j9xrTvB/xoEv1PAq7MzF9O5sUuueQSFi5c2FqF\nkiTNEuN9+N6yZQuLFi2a0v5aWaPxLuDKiLiL6qyTs6b0imNk5ghVeDlqZ1tEROPxLbvrGxEvBp5C\ndYVSSZLUYSY9opGZV0XE9cBBwHcz86fTWMfFwNqIGARupToLZW8aZ5FExPnAAZn52jH9Xg9szsyh\naaxFkiRNk5budZKZ9wL3TncRmXl145oZ76WaMrkNWJKZdzc22Z9quuZXIuI3gJdTXVNDkiR1oEkF\njYj4FPBnmfmzSW5/FbCqcY2LScnMS4FLJ3jupHHafgaMvf+KJEnqIJMd0Tge+K1q6cTDCmAZ1RqO\nSQcNSZLUfSYbNILqdvCSJEmTNtmg8ftT2Pd/TqGPJEnqIpMKGo0rgEqSJLWk5ZuqSZIkTZZBQ5Ik\nFWPQkCRJxRg0JElSMVMKGhGxZ0QcHRFvjoi+RtsBEeEFtCRJ0q+0dAlygIj4HeB64LeBRwOfB4aB\ndzYenzydBUqSpJlrKiMaq4GvAL8J3N/U/mma7sAqSZLU8ogGcCTwgsz8xZhLkt8BHDgdRUmSpO4w\nlRGNHmCPcdqfTDWFIkmSBEwtaNwA/M+mx9lYBPoe4HPTUpUkSeoKU5k6OQ1YHxHfAvYCPgE8FbgH\n6J/G2iRJ0gzXctDIzDsj4jnACcBzgMcBHwOuysz7d9tZkiTNKi0FjYjoBS4D3peZVwFXFalKkiR1\nhZbWaGTmCLC8UC2SJKnLTGUx6GeAl013IZIkqftMZTHod4F3R8ThwCCwo/nJzPzQdBQmSZJmvqkE\njdcDPwUWNb6aJWDQkCRJwNTOOplfohBJktR9HtFt4qNhuoqRJEndZaq3iT8xIr5BdVO1+yPi6xHx\np9NbmiRJmummcpv4U4H3AR8BNjSajwA+GhH7ZuYl01ifJEmawaayGPRtwFsy88qmtnUR8U3gHMCg\nIUmSgKlNnTwJuGWc9lsaz0mSJAFTCxr/BrxynPYTqK6xIUmSBExt6uRs4JMR8UJ2rdE4HDiK8QOI\nJEmapVoe0cjMa4DnU90W/mWNr3uAwzLz09NbniRJmsmmMqJBZg4Cr5nmWiRJUpdpeUQjIv4wIpaM\n074kIl4yPWVJkqRuMJXFoO+foD1285wkSZqFphI0ngp8e5z224GDH1k5kiSpm0wlaGwHDhqn/WDG\n3DJekiTNblMJGv8AfDAinrKzISIOBi4C1k1XYZIkaeabStB4B9XIxe0RsTUitgJDwL3A6dNZnCRJ\nmtlaPr01M7dHxAuAY4DnUN3B9euZ+U/TXZwkSZrZpnodjQRuaHxJkiSNa9JTJxGxOCL+aEzbiY3p\nkx9HxF9HxKOnv0RJkjRTtbJG493As3Y+iIjfBT4G3Eh1/YxlwLumtTpJkjSjtRI0ngvc1PT4VcDm\nzHxjZl4MrMSbqkmSpCatBI3fBLY1PX4RcF3T4y8Dc6ejKEmS1B1aCRrbgPkAEfEoYCGwqen5PmBk\n+kqTJEkzXStB43PA+yPiSOB84D7gn5uefzbw79NYmyRJmuFaOb31LOBTwJeAnwOvzcxfND3/Ojzd\nVZIkNZl00MjMe4AXRsQc4OeZ+eCYTV5BFUAkSZKAKV4ZdIL2nzzyciRJUjeZyr1OJEmSJsWgIUmS\nijFoSJKkYgwakiSpGIOGJEkqxqAhSZKKMWhIkqRiDBqSJKkYg4YkSSrGoCFJkorpmKAREadExNaI\nuD8iNkXEoQ+z/aMi4ryIuCMiHoiI70XEn7WpXEmSNAkt3+ukhIg4AbgIeBNwK7AKWB8RT2vczG08\nfw/8FnAS1e3pn0QHBSdJktQhQYMqWFyWmVcCRMTJwEupbj1/wdiNI2IpcCRwUGb+tNH8H22qVZIk\nTVLtIwAR0QssAm7a2ZaZCdwILJ6g2zLgK8A7I+LOiPh2RHwgIvYqXrAkSZq0ThjR2BfYA9g2pn0b\n8PQJ+hxENaLxAPCyxj7+Cng88PoyZUqSpFZ1QtCYih5gFPiTzPw5QEScCvx9RLw1M/97oo6rVq1i\nzpw5D2nr7++nv7+/ZL2SJM0IAwMDDAwMPKRt+/btU95fVLMU9WlMndwHLM/MdU3ta4E5mfnycfqs\nBV6QmU9ransG8E3gaZn57+P0WQgMDg4OsnDhwmn/PiRJ6lZbtmxh0aJFAIsyc0srfWtfo5GZI8Ag\ncNTOtoiIxuNbJui2ATggIvZuans61SjHnYVKlSRJLao9aDRcDLwxIk5sjEx8FNgbWAsQEedHxMeb\ntv8EcC9wRUQsiIgXUp2d8rHdTZtIkqT26og1Gpl5dUTsC7wX2A+4DViSmXc3NtkfmNu0/Y6IOAb4\nMPBlqtDxSeCsthYuSZJ2qyOCBkBmXgpcOsFzJ43T9h1gSem6JEnS1HXK1IkkSepCBg1JklSMQUOS\nJBVj0JAkScUYNCRJUjEGDUmSVIxBQ5IkFWPQkCRJxRg0JElSMQYNSZJUjEFDkiQVY9CQJEnFGDQk\nSVIxBg1JklSMQUOSJBVj0JAkScUYNCRJUjEGDUmSVIxBQ5IkFWPQkCRJxRg0JElSMQYNSZJUjEFD\nkiQVY9CQJEnFGDQkSVIxBg1JklSMQUOSJBVj0JAkScUYNCRJUjEGDUmSVIxBQ5IkFWPQkCRJxRg0\nJElSMQYNSZJUjEFDkiQVY9CQJEnFGDQkSVIxBg1JklSMQUOSJBVj0JAkScUYNCRJUjEGDUmSVIxB\nQ5IkFWPQkCRJxRg0JElSMQYNSZJUjEFDkiQVY9CQJEnFGDQkSVIxBg1JklSMQUOSJBVj0JAkScUY\nNCRJUjEGDUmSVIxBQ5IkFWPQkCRJxRg0JElSMQYNSZJUTMcEjYg4JSK2RsT9EbEpIg7dzbYviojR\nMV8PRsQT21mzJEnavY4IGhFxAnARcDZwCPA1YH1E7Lubbgk8Fdi/8fWkzPxx6VolSdLkdUTQAFYB\nl2XmlZl5O3AycB/wuofpd3dm/njnV/EqJUlSS2oPGhHRCywCbtrZlpkJ3Ags3l1X4LaIuCsiboiI\nF5StVJIktar2oAHsC+wBbBvTvo1qSmQ8PwTeDCwH/hj4AfDFiHhuqSIlSVLr9qy7gKnIzO8A32lq\n2hQRT6Gagnnt7vquWrWKOXPmPKStv7+f/v7+aa9TkqSZZmBggIGBgYe0bd++fcr7i2qWoj6NqZP7\ngOWZua6pfS0wJzNfPsn9XAAcnpmHT/D8QmBwcHCQhQsXPvLCJUmaJbZs2cKiRYsAFmXmllb61j51\nkpkjwCBw1M62iIjG41ta2NVzqaZUJElSh+iUqZOLgbURMQjcSjUFsjewFiAizgcOyMzXNh6/HdgK\nfBPYC3gj8PvAMW2vXJIkTagjgkZmXt24ZsZ7gf2A24AlmXl3Y5P9gblNXR5Fdd2NA6imXb4OHJWZ\n/9S+qiVJ0sPpiKABkJmXApdO8NxJYx5/APhAO+qSJElTV/saDUmS1L0MGpIkqRiDhiRJKsagIUmS\nijFoSJKkYgwakiSpGIOGJEkqxqAhSZKKMWhIkqRiDBqSJKkYg0aNMrPuEiRJKsqg0WbDw8OsXHk2\n8+cfzdy5L2P+/KNZufJshoeH6y5NkqRp1zE3VZsNhoeHWbx4OUNDpzI6eg4QQLJmzXpuvnk5Gzde\nQ19fX81VSpI0fRzRaKMzzriwETKWUoUMgGB0dClDQ6s488yL6ixPkqRpZ9Boo2uv3cDo6JJxnxsd\nXcq6dRvaXJEkSWUZNNokMxkZeSy7RjLGCkZG9naBqCSpqxg02iQi6O3dAUwUJJLe3h1ETBREJEma\neQwabbRs2eH09Kwf97menus57rgj2lyRJEllGTTa6LzzTmfBgovp6bmOXSMbSU/PdSxYcAnnnnta\nneVJkjTtDBpt1NfXx8aN17BixWbmzTuWAw88nnnzjmXFis2e2ipJ6kpeR6PN+vr6WL36HFavrhaI\nuiZDktTNHNGokSFDktTtDBqSJKkYg8YsNDAwUHcJHcHjsIvHouJx2MVjUfE4PHIGjVnIX5yKx2EX\nj0XF47CLx6LicXjkDBqSJKkYg4YkSSrGoCFJkoqZTdfR2AtgaGio7jpqt337drZs2VJ3GbXzOOzi\nsah4HHbxWFQ8DpWm9869Wu0bs+VuoRHxJ8BVddchSdIM9urM/EQrHWZT0HgCsAS4A3ig3mokSZpR\n9gLmAesz895WOs6aoCFJktrPxaCSJKkYg4YkSSrGoCFJkooxaEiSpGJmZdCIiKdGxGci4u6I2B4R\n/xwRL667rjpExEsjYlNE3BcRP4mIT9VdU50i4lERcVtEjEbEs+uup50i4nci4m8i4nuNn4fvRsQ5\nEdFbd23tEBGnRMTWiLi/8TtxaN01tVNEvCsibo2In0XEtoj4dEQ8re666hYRf9H4e3Bx3bXUISIO\niIj/GxH3NP4ufC0iFrayj1kZNIDPAnsALwYWAl8D/jEinlhnUe0WEcuBK4GPAb8LvABo6fzoLnQB\ncCcwG0/HegYQwBuBZwKrgJOB8+osqh0i4gTgIuBs4BCqvwnrI2LfWgtrryOBDwPPB44GeoEbIuIx\ntVZVo0bYfBPVz8OsExH7ABuA/6a6PMQC4DTgv1raz2w7vbVxPY27gSMzc0Oj7XHAz4CjM/PmOutr\nl4jYg+qaImdl5tp6q+kMEfES4EJgOfAt4LmZ+fV6q6pXRJwOnJyZB9ddS0kRsQnYnJlvbzwO4AfA\nhzLzglqLq0kjZP0YeGFm/kvd9bRb431hEHgLcBbw1cw8td6q2isi3g8szswXPZL9zLoRjcaFRm4H\nToyIvSNiT6ofpG1UP1SzxULgAICI2BIRd0XE5yLiWTXXVYuI2A/4a+A1wP01l9NJ9gF+UncRJTWm\nhhYBN+1sy+oT2I3A4rrq6gD7UI3sdfW//26sAa6dLR8+J7AM+EpEXN2YTtsSEW9odSezLmg0HEP1\nRjtM9abydmBpZm6vtar2OohqmPxs4L3AS6mGw77YGC6bba4ALs3Mr9ZdSKeIiIOBFcBH666lsH2p\nplK3jWnfBuzf/nLq1xjR+SDwL5n5rbrrabeIeBXwXOBddddSs4OoPoh/GzgW+CvgQxHxp63spGuC\nRkSc31iwM9HXg00Lmy6l+iNyOHAo8BmqNRr71VX/dGnhOOz8tz83Mz/TeIM9ieoTzCtq+wam0WSP\nRUSsBB4H/O+dXWsse9q1+Luxs8+BwHXAJzPz/9RTuWp0KdU6nVfVXUi7RcSTqULWqzNzpO56atYD\nDGbmWZn5tcy8HLicau3WpHXNGo3G2osnPMxm3wNeBFwP7JOZO5r6fwf4m5k+H9vCcTgCuBk4IjNv\naeq/Cfh8Zp5Vrsr2mOSx2ApcDfzRmPY9gF8CV2XmSQXKa5vJ/kxk5i8b2x8AfAG4ZaZ/75PRmDq5\nD1iemeua2tcCczLz5XXVVoeI+AjVkPmRmfkfddfTbhFxPPAp4EF2fejYg+pD2IPAo7Nb3jgfRkTc\nAdyQmW9qajsZOCMz5052P11zm/jG2ouHvdFLYwV1AqNjnhqlC0Z4WjgOg1QriZ8O3NJo66W6ac73\nC5bYNi0ci7cBZzQ1HQCsB14J3FqmuvaZ7HGAX41k3Ax8GXhdybo6RWaONH4fjgLWwa+mDo4CPlRn\nbe3WCBnHAy+ajSGj4Uaqs/CarQWGgPfPlpDRsIHqPaLZ02nxPaJrgkYLNgI/Ba6MiPdRrdF4E9Ub\n7GdrrKutMnM4Ij4KvCci7qT6wXkHVQj7+1qLa7PMvLP5cUTsoPok873MvKueqtqvMZLxRapRnncA\nT6zebyEzx65f6DYXA2sbgeNWqlN796Z6g5kVIuJSoB84DtjRNJW8PTNnzR2vGyPdD1mX0vibcG9m\nDtVTVW0uATZExLuoRn6fD7yB6hT4SZt1QSMz742IpVTXBriJ6lzxbwLHZeY3ai2u/U4HRqiupfEY\nYDPwB7NsUexEZtOnlp2OoVr8dRDVqZ1QBa6kGjruWpl5deN0zvcC+wG3AUsy8+56K2urk6n+rb84\npv0kqr8Rs9ls/HtAZn4lIl4OvJ/qFN+twNsz8+9a2U/XrNGQJEmdZ8avSZAkSZ3LoCFJkooxaEiS\npGIMGpIkqRiDhiRJKsagIUmSijFoSJKkYgwakiSpGIOGJEkqxqAhqSNFRG9EfDcifq/Ffksi4qul\n6pLUGoOGpJZFxBUR8anCL/MWqhvbbRrz2r8fEZ+NiHsiYkdE/GtEXNi4KRyZuR74RUS8unB9kibB\noCGpU50C/E1zQ0S8Gfg8cBfwx8ACqpuB/QZwatOmHwfe3p4yJe2ON1WT1LKIuAKYk5l/PM5zc4GP\nAH8AjALXA2/LzB83bXMm8Dbg0cDfAT8BXpKZhzSefx6wEdincdtuIuJA4N+Bj2Tm6eO87m9k5s+a\navg+8JRaQc43AAACZUlEQVTM3Dpt37ikljmiIWnaREQA64B9gCOBo6luO/93Tdu8GvhfwJ8DzwP+\nE3grD70V9xHAd3aGjIZXAr3AB8Z77Z0ho/H/PwC2NWqQVKM96y5AUlc5GngWMC8z7wKIiBOBb0bE\noswcBFYAl2fmlY0+74uIY4HHNu3nd6imR5odDPwsM7dNspa7GvuRVCNHNCRNp2cAP9gZMgAycwj4\nKdV6CoCnA18e0+/WMY8fAzwwpi146KjHw7kf2LuF7SUVYNCQ1InuAX5zTNt3gDkRsd8k9/F44O5p\nrUpSywwakqbTEDC3sXATgIh4JtWajW82mr4NHDqm39jHX6UaHWn2/4AR4B3jvXBEzGn6/0cDT2ns\nR1KNXKMhaar2iYjnjGm7HfgGcFVErKJavLkG+EJm7nzT/zBweUQMArcArwKeTXVGyU5fAB4XEc/M\nzG8BZOadjX1+uBEqrgTuAJ4MnAgMUy0wBVhMNfWycRq/X0lT4IiGpKl6EbBlzNe7geOp1mR8CbgB\n+DeqMAFAZn4C+Euqs0cGqRZsrqVpTUZm/gT4NPCa5hfMzL8CjgUOAD5FNYJyOfBL4INNm74KuCoz\nx67zkNRmXkdDUu0i4gbgh5n52qa236UKKk/JzPta2NcTqEZWnpeZ35/2YiW1xKkTSW0VEY+huprn\neqoLevUDR1GdGvsrmfmNiHgnMJ9d6zsmYx7wVkOG1Bkc0ZDUVhGxF3At8FxgL6rFoe/LzH+otTBJ\nRRg0JElSMS4GlSRJxRg0JElSMQYNSZJUjEFDkiQVY9CQJEnFGDQkSVIxBg1JklSMQUOSJBXz/wHP\nBiJ1XONGUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b36630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ = np.log(parametric_score[0])\n",
    "y_ = parametric_score[1]\n",
    "plt.plot(x_ , y_ , 'o')\n",
    "\n",
    "#plt.xlim([-12, 1])\n",
    "#plt.ylim([0.7, 1])\n",
    "plt.xlabel(\"Log(C)\")\n",
    "plt.ylabel(\"Score [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Data_Evaluate(Datos):\n",
    "    \n",
    "    #def __init__(self, name):\n",
    "    #    file_train = \"COPIA.xlsx\"\n",
    "    #    wb = openpyxl.load_workbook(file_train)\n",
    "    #    self.sheet = wb.get_sheet_by_name('Sheet1')\n",
    "    #    self.sheet = wb.active\n",
    "    #    #self.sheet.cell(row=2, column=20).value = \"THIS IS SPARTA\" \n",
    "    \n",
    "    def OneHotEncoding_SCORE(self, encoder):\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18]\n",
    "        examples = len(self.data_matrix[:,0])\n",
    "        categorical = []\n",
    "        \n",
    "        \n",
    "        for i in range(examples):\n",
    "            example_categorical = []\n",
    "            for index in non_numerical_columns:\n",
    "                example_categorical.append(self.data_matrix[i][index])\n",
    "            categorical.append(example_categorical)\n",
    "                \n",
    "\n",
    "        hot = encoder.transform(categorical).toarray()\n",
    "        \n",
    "        len_one_hot = sum(encoder.n_values_)\n",
    "        \n",
    "        self.data = []\n",
    "        for i in range(examples):\n",
    "            one_hot = hot[i]\n",
    "            row_data = []\n",
    "            # Add numerical info\n",
    "            for j in range(self.cols):\n",
    "                if not j in non_numerical_columns:\n",
    "                    row_data.append(self.data_matrix[i][j])\n",
    "                   \n",
    "            # Add categorical info\n",
    "            output = self.add_categorical_one_hot(row_data, one_hot)            \n",
    "            self.data.append(output)\n",
    "\n",
    "\n",
    "    def evaluate(self, encoder, model):\n",
    "        self.OneHotEncoding_SCORE(encoder)\n",
    "        self.data_score = np.asarray(self.data)\n",
    "        \n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "        imp.fit(self.data_score)\n",
    "        self.data_score = imp.transform(self.data_score)\n",
    "        \n",
    "        print \"Largo\", len(self.data_score[1:0])\n",
    "        \n",
    "        self.prediction = model.predict(self.data_score[:,1:])        \n",
    "        \n",
    "        return self.prediction\n",
    "   \n",
    "    def write_excel(self):\n",
    "        file_train = \"COPIA.xlsx\"\n",
    "        wb = openpyxl.load_workbook(file_train)\n",
    "        self.sheet = wb.get_sheet_by_name('Sheet1')\n",
    "        self.sheet = wb.active\n",
    "        write_row = 2\n",
    "        for score_pred in self.prediction:\n",
    "            if score_pred == 1:  ## Paga\n",
    "                self.sheet.cell(row=write_row, column=20).value = \"PAGA\"\n",
    "            else:\n",
    "                self.sheet.cell(row=write_row, column=20).value = \"NO PAGA\"\n",
    "            write_row += 1\n",
    "        \n",
    "        wb.save('salida.xlsx')\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporando a matriz: GENERO\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'F       ' u'M       ']\n",
      "Incorporando a matriz: RENTA\n",
      "Incorporando a matriz: EDAD\n",
      "Incorporando a matriz: NIV_EDUC\n",
      "[ 0.  1.  2.  3.  4.  5.  6.]\n",
      "Labels:  [u'        ' u'0' u'BAS     ' u'EUN     ' u'MED     ' u'TEC     '\n",
      " u'UNV     ']\n",
      "Incorporando a matriz: E_CIVIL\n",
      "[ 0.  1.  2.  3.  4.]\n",
      "Labels:  [u'0' u'CAS     ' u'SEP     ' u'SOL     ' u'VIU     ']\n",
      "Incorporando a matriz: COD_OFI\n",
      "Incorporando a matriz: COD_COM\n",
      "Incorporando a matriz: CIUDAD\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.]\n",
      "Labels:  [u'                ' u'0' u'ANCUD           ' u'ANGOL           '\n",
      " u'ANTOFAGASTA     ' u'ARICA           ' u'AYSEN           '\n",
      " u'CALAMA          ' u'CALBUCO         ' u'CALDERA         '\n",
      " u'CASABLANCA      ' u'CASTRO          ' u'CHILLAN         '\n",
      " u'CHUQUICAMATA    ' u'COLBUN          ' u'CON-CON         '\n",
      " u'CONCEPCION      ' u'COPIAPO         ' u'COQUIMBO        '\n",
      " u'CORONEL         ' u'COYHAIQUE       ' u'CURACAVI        '\n",
      " u'CURICO          ' u'DONIHUE         ' u'EL QUISCO       '\n",
      " u'EL SALVADOR     ' u'FRESIA          ' u'HIJUELAS        '\n",
      " u'HUASCO          ' u'IQUIQUE         ' u'LA CALERA       '\n",
      " u'LA CRUZ         ' u'LA SERENA       ' u'LINARES         '\n",
      " u'LLANQUIHUE      ' u'LLO-LLEO        ' u'LONCOCHE        '\n",
      " u'LOS ANDES       ' u'LOS ANGELES     ' u'LOS LAGOS       '\n",
      " u'LOS MUERMOS     ' u'LOS VILOS       ' u'MACHALI         '\n",
      " u'MELIPILLA       ' u'MOLINA          ' u'OSORNO          '\n",
      " u'OVALLE          ' u'PALENA          ' u'PANGUIPULLI     '\n",
      " u'PARRAL          ' u'PENAFLOR        ' u'PENCO           '\n",
      " u'PETORCA         ' u'PUERTO MONTT    ' u'PUERTO OCTAY    '\n",
      " u'PUERTO VARAS    ' u'PUNTA ARENAS    ' u'QUILLOTA        '\n",
      " u'QUILPUE         ' u'RANCAGUA        ' u'RENGO           '\n",
      " u'ROMERAL         ' u'SAN ANTONIO     ' u'SAN CLEMENTE    '\n",
      " u'SAN ESTEBAN     ' u'SAN FELIPE      ' u'SAN FERNANDO    '\n",
      " u'SAN PABLO       ' u'SAN PEDRO       ' u'SANTA CRUZ      '\n",
      " u'SANTA MARIA     ' u'SANTIAGO        ' u'STO DOMINGO     '\n",
      " u'TALAGANTE       ' u'TALCA           ' u'TALCAHUANO      '\n",
      " u'TEMUCO          ' u'TOCOPILLA       ' u'VALDIVIA        '\n",
      " u'VALLENAR        ' u'VALPARAISO      ' u'VILLARRICA      '\n",
      " u'VINA DEL MAR    ' u'VLLA ALEMANA    ']\n",
      "Incorporando a matriz: Crédito_1\n",
      "Incorporando a matriz: Crédito_2\n",
      "Incorporando a matriz: Crédito_3\n",
      "Couldn't fill missing values of  Crédito_3\n",
      "Incorporando a matriz: Crédito_4\n",
      "Incorporando a matriz: Monto solicitado\n",
      "Incorporando a matriz: Días de Mora\n",
      "Incorporando a matriz: Monto Deuda Promedio\n",
      "Incorporando a matriz: Número de meses inactivo\n",
      "Incorporando a matriz: numero de cuotas\n",
      "Incorporando a matriz: Aval\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [u'0' u'NO' u'SI']\n",
      "[ 0.  1.]\n",
      "Labels:  [u'NO PAGA' u'PAGA']\n",
      "Imposible de transformar  PAGA\n",
      "PAGA No added\n",
      "Largo 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:391: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    }
   ],
   "source": [
    "#train_datos = Datos('CREDITRISK_SCORE.xlsx')\n",
    "#data_matrix = train_datos.get_matrix()\n",
    "#train_datos.OneHotEncoding()\n",
    "\n",
    "score_datos = Data_Evaluate('CREDITRISK_SCORE.xlsx')\n",
    "score_datos.preprocess(False, train_datos.Label_Encoders)\n",
    "\n",
    "#score_datos.evaluate(train_datos.OHE, modelo)\n",
    "\n",
    "modelo = RF\n",
    "score_prediction = score_datos.evaluate(train_datos.OHE, modelo)\n",
    "\n",
    "score_datos.write_excel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
