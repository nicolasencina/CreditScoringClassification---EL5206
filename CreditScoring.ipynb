{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aadiendo: GENERO\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [None u'F       ' u'M       ']\n",
      "Aadiendo: RENTA\n",
      "Aadiendo: EDAD\n",
      "Aadiendo: NIV_EDUC\n",
      "[ 0.  1.  2.  3.  4.  5.  6.]\n",
      "Labels:  [None u'        ' u'BAS     ' u'EUN     ' u'MED     ' u'TEC     '\n",
      " u'UNV     ']\n",
      "Aadiendo: E_CIVIL\n",
      "[ 0.  1.  2.  3.  4.]\n",
      "Labels:  [None u'CAS     ' u'SEP     ' u'SOL     ' u'VIU     ']\n",
      "Aadiendo: COD_OFI\n",
      "Aadiendo: COD_COM\n",
      "Aadiendo: CIUDAD\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.]\n",
      "Labels:  [None u'                ' u'ANCUD           ' u'ANGOL           '\n",
      " u'ANTOFAGASTA     ' u'ARICA           ' u'AYSEN           '\n",
      " u'CALAMA          ' u'CALBUCO         ' u'CALDERA         '\n",
      " u'CASABLANCA      ' u'CASTRO          ' u'CHILLAN         '\n",
      " u'CHUQUICAMATA    ' u'COLBUN          ' u'CON-CON         '\n",
      " u'CONCEPCION      ' u'COPIAPO         ' u'COQUIMBO        '\n",
      " u'COYHAIQUE       ' u'CURACAVI        ' u'CURICO          '\n",
      " u'DONIHUE         ' u'EL QUISCO       ' u'EL SALVADOR     '\n",
      " u'HIJUELAS        ' u'HUASCO          ' u'IQUIQUE         '\n",
      " u'LA CALERA       ' u'LA CRUZ         ' u'LA SERENA       '\n",
      " u'LINARES         ' u'LLANQUIHUE      ' u'LLO-LLEO        '\n",
      " u'LONCOCHE        ' u'LOS ANDES       ' u'LOS ANGELES     '\n",
      " u'LOS LAGOS       ' u'LOS MUERMOS     ' u'LOS VILOS       '\n",
      " u'MACHALI         ' u'MELIPILLA       ' u'MOLINA          '\n",
      " u'OSORNO          ' u'OVALLE          ' u'PALENA          '\n",
      " u'PANGUIPULLI     ' u'PARRAL          ' u'PENAFLOR        '\n",
      " u'PENCO           ' u'PETORCA         ' u'PUERTO MONTT    '\n",
      " u'PUERTO OCTAY    ' u'PUERTO VARAS    ' u'PUNTA ARENAS    '\n",
      " u'QUILLOTA        ' u'QUILPUE         ' u'RANCAGUA        '\n",
      " u'RENGO           ' u'ROMERAL         ' u'SAN ANTONIO     '\n",
      " u'SAN CLEMENTE    ' u'SAN FELIPE      ' u'SAN FERNANDO    '\n",
      " u'SAN PEDRO       ' u'SANTA MARIA     ' u'SANTIAGO        '\n",
      " u'STO DOMINGO     ' u'TALAGANTE       ' u'TALCA           '\n",
      " u'TALCAHUANO      ' u'TEMUCO          ' u'TOCOPILLA       '\n",
      " u'VALDIVIA        ' u'VALLENAR        ' u'VALPARAISO      '\n",
      " u'VILLARRICA      ' u'VINA DEL MAR    ' u'VLLA ALEMANA    ']\n",
      "Aadiendo: Crédito_1\n",
      "Aadiendo: Crédito_2\n",
      "Aadiendo: Crédito_3\n",
      "Aadiendo: Crédito_4\n",
      "Aadiendo: Monto solicitado\n",
      "Aadiendo: Días de Mora\n",
      "Aadiendo: Monto Deuda Promedio\n",
      "Aadiendo: Número de meses inactivo\n",
      "Aadiendo: numero de cuotas\n",
      "Aadiendo: Aval\n",
      "[ 0.  1.  2.]\n",
      "Labels:  [None u'NO' u'SI']\n",
      "[ 0.  1.]\n",
      "Labels:  [u'NO PAGA' u'PAGA']\n",
      "PAGA no added\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class Datos:\n",
    "    def __init__(self, name, rows):\n",
    "        ## Abrir Excel con Datos\n",
    "        file_train = name\n",
    "        wb = openpyxl.load_workbook(file_train)\n",
    "        sheet = wb.get_sheet_by_name('Sheet1')\n",
    "        sheet = wb.active\n",
    "        self.rows = rows\n",
    "\n",
    "        # Forma matriz para contener datos\n",
    "        columns = 20 \n",
    "        self.cols_init = columns\n",
    "        self.data_matrix = np.zeros(shape=(self.rows, columns))\n",
    "        self.cols = columns\n",
    "        self.target = np.zeros(shape=(self.rows, 1))\n",
    "        \n",
    "        # Columnas con datos no numericos, se deben pasar a labels numericos usando un LabelEncoder\n",
    "        non_numerical_columns = [1, 4, 5, 8, 18, 19]  ##\n",
    "        non_numerical_info = []\n",
    "        clases = []\n",
    "        clases_num_encode = []\n",
    "        self.features_names = []\n",
    "        empty_cell = sheet.cell(row=85, column=8).value  ## Ejemplo de celda vacia\n",
    "\n",
    "        for i in range(columns):\n",
    "            j = 0\n",
    "            column_i = []\n",
    "\n",
    "            flag_non_numeric = False\n",
    "            flag_append = True\n",
    "\n",
    "            # Verificar si la columna es de datos no numericos\n",
    "            if i in non_numerical_columns:\n",
    "                flag_non_numeric = True\n",
    "\n",
    "            for cellObj in sheet.columns[i]:\n",
    "                if j > 0:\n",
    "                    if (cellObj.value == empty_cell) and (not flag_non_numeric):\n",
    "                    #if (cellObj.value == empty_cell):\n",
    "                        #flag_append = False\n",
    "                        column_i.append(0)\n",
    "                    else:\n",
    "                        column_i.append(cellObj.value)\n",
    "\n",
    "                else:\n",
    "                    name = cellObj.value\n",
    "                    if i>0:\n",
    "                        if i != self.cols -1:\n",
    "                            self.features_names.append(name)\n",
    "                            print \"Aadiendo: \" + name\n",
    "\n",
    "\n",
    "                j += 1\n",
    "\n",
    "\n",
    "            if flag_non_numeric:\n",
    "                le = preprocessing.LabelEncoder()\n",
    "                le.fit(column_i)\n",
    "                clases.append(list(le.classes_))\n",
    "\n",
    "                n_clases = len(le.classes_)\n",
    "                ordered_clases = np.linspace(0, n_clases - 1, n_clases)\n",
    "                inverse_ordered = le.inverse_transform(list(ordered_clases.astype(int)))\n",
    "                print ordered_clases\n",
    "                print \"Labels: \", str(inverse_ordered)\n",
    "\n",
    "                non_numerical_info.append(sheet.cell(row=1, column=i+1).value)\n",
    "\n",
    "                #enc = preprocessing.OneHotEncoder()\n",
    "                #enc.fit(le.transform(column_i))\n",
    "                #print enc.transform(le.transform(column_i)).toarray()\n",
    "\n",
    "                # Encode de datos\n",
    "                column_i = le.transform(column_i)\n",
    "\n",
    "                # Encode de datos con OneHot Encode\n",
    "                #column_i = enc.transform(le.transform(column_i)).toarray()\n",
    "\n",
    "            if flag_append and i < self.cols - 1:\n",
    "                self.data_matrix[:,i] = column_i\n",
    "            else:\n",
    "                print name + \" no added\"\n",
    "                \n",
    "            if i == self.cols - 1:\n",
    "                self.target = column_i\n",
    "             \n",
    "        \"\"\"\n",
    "        self.target = np.zeros(shape=(rows, 1))\n",
    "        j = 0\n",
    "        for cellObj in sheet.columns[columns - 1]:\n",
    "            if j>0:\n",
    "                dato = cellObj.value \n",
    "                if dato == \"PAGA\":\n",
    "                    self.target[i] = 1\n",
    "                elif dato == \"NO PAGA\":\n",
    "                    self.target[i] = 0\n",
    "                else:\n",
    "                    print \"WTF\"\n",
    "            j += 1\n",
    "         \"\"\"\n",
    "    def feat_names(self):\n",
    "        return self.features_names\n",
    "    \n",
    "    def get_target(self):\n",
    "        return self.target\n",
    "    \n",
    "    def get_matrix(self):\n",
    "        return self.data_matrix\n",
    "    \n",
    "    def add_sum(self):\n",
    "        self.cols += 1\n",
    "        self.new_data_matrix = np.zeros(shape=(self.rows, self.cols))\n",
    "        self.new_data_matrix[:,0:self.cols - 1] = self.data_matrix \n",
    "        \n",
    "        for j in range(len(self.data_matrix[:,0])):\n",
    "            a = self.data_matrix[j,9] + self.data_matrix[j,10] \n",
    "            b = self.data_matrix[j,11] + self.data_matrix[j,12]\n",
    "            self.new_data_matrix[j, - 1] = (a + b)/4\n",
    "        \n",
    "        self.data_matrix = self.new_data_matrix\n",
    "        self.features_names.append(\"Suma Creditos\")\n",
    "        \n",
    "    def add_cuota_promedio(self):\n",
    "        self.cols += 1\n",
    "        self.new_data_matrix = np.zeros(shape=(self.rows, self.cols))\n",
    "        self.new_data_matrix[:,0:self.cols - 1] = self.data_matrix \n",
    "        \n",
    "        for j in range(len(self.data_matrix[:,0])):\n",
    "            a = self.data_matrix[j,13]  \n",
    "            b = self.data_matrix[j,17] \n",
    "            self.new_data_matrix[j, - 1] = a / b\n",
    "        \n",
    "        self.data_matrix = self.new_data_matrix\n",
    "        self.features_names.append(\"Cuota Promedio\")\n",
    "        \n",
    "                \n",
    "train_datos = Datos('CREDITRISK_RAW.xlsx', 2294)\n",
    "data_matrix = train_datos.get_matrix()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminar NaN values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(data_matrix)\n",
    "\n",
    "data_matrix = imp.transform(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Calculo de caracteristicas\n",
    "\n",
    "start_money_values = 9\n",
    "finish_money_values = 12\n",
    "\n",
    "\"\"\"\n",
    "for i in range(12-9):\n",
    "    for j in range(len(data_matrix[:,0])):\n",
    "        sueldo = data_matrix[j,2]\n",
    "        data_matrix[:,9+i] = data_matrix[:,9+i]/sueldo \n",
    "\"\"\"\n",
    "\n",
    "train_datos.add_sum()\n",
    "train_datos.add_cuota_promedio()\n",
    "data_matrix = train_datos.get_matrix()\n",
    "\n",
    "\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(data_matrix)\n",
    "\n",
    "data_matrix = imp.transform(data_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importances(clf, X, X_test):\n",
    "    importances = clf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    features_names = train_datos.feat_names()\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "\n",
    "        #print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        print str(f+1)+\". \"+ features_names[indices[f]] + \": \"+str(importances[indices[f]])\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X_test.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "    #plt.xticks(range(X_test.shape[1]), indices)\n",
    "    plt.xlim([-1, X_test.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASES HISTOGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Graficos en base a las caracteristicas más importantes según Random Forest\n",
    "\n",
    "class Histogram:\n",
    "    \n",
    "    def __init__(self, data_matrix, target_matrix, feature_index, name):\n",
    "        self.name = name\n",
    "        self.index = feature_index\n",
    "        rows = len(target_matrix)\n",
    "        self.data = np.zeros(shape=(rows, 2))\n",
    "        \n",
    "        _columns = len(data_matrix[0,:])\n",
    "        self.data[:,0] = data_matrix[:, self.index]\n",
    "        #self.data[:,1] = data_matrix[:, _columns - 1]\n",
    "        self.data[:,1] = target_matrix\n",
    "        \n",
    "        _N_datos = len(self.data[:,0])\n",
    "        self.convert_data = np.zeros( shape = (_N_datos, 2))\n",
    "    \n",
    "        _Paga = 1;\n",
    "        _NoPaga = 0;\n",
    "\n",
    "        self.paga_hist = []\n",
    "        self.no_paga_hist = []\n",
    "\n",
    "        for i in range(_N_datos):\n",
    "            if self.data[i,1] == _Paga:\n",
    "                self.paga_hist.append( self.data[i,0])\n",
    "            else:\n",
    "                self.no_paga_hist.append( self.data[i,0])\n",
    "                \n",
    "        self.discrete = False\n",
    "\n",
    "\n",
    "    def set_bins(self, init_range, final_range, nbins):\n",
    "        self.bins = plt.linspace(init_range, final_range, nbins)\n",
    "        self.nbins = nbins\n",
    "        self.xlims = [init_range-0.5, final_range+0.5]\n",
    "        print self.bins\n",
    "        \n",
    "    def is_discrete(self, discrete):\n",
    "        init_range = 0\n",
    "        final_range = discrete+0.5 \n",
    "        nbins = discrete + 1\n",
    "        self.bins = plt.linspace(init_range, final_range, nbins)\n",
    "        self.nbins = discrete\n",
    "        self.bar_l = plt.linspace(0,discrete-1, discrete)\n",
    "        self.xlims = [-0.5, discrete+0.5]\n",
    "        self.discrete = True\n",
    "\n",
    "    def set_xlim(self, array):\n",
    "        self.xlims = array\n",
    "    \n",
    "    def hist(self):\n",
    "        _paid = self.paga_hist\n",
    "        _no_paid = self.no_paga_hist\n",
    "            \n",
    "        x = [_paid, _no_paid]\n",
    "        self.histo = plt.hist(x, self.bins)\n",
    "        plt.clf()\n",
    "\n",
    "        _to_bar_1 = self.histo[0][0]\n",
    "        _to_bar_2 = self.histo[0][1]\n",
    "\n",
    "        # Create the general blog and the \"subplots\" i.e. the bars\n",
    "        f, ax1 = plt.subplots(1, figsize=(10,5))\n",
    "\n",
    "        # Set the bar width\n",
    "        bar_width = 0.75\n",
    "        bar_width = (self.bins[self.nbins-1] - self.bins[0])/(self.nbins)\n",
    "\n",
    "        # positions of the left bar-boundaries\n",
    "        #bar_l = [(i+1)*2.5 for i in range(len(_to_bar_1))] #+ self.bins[0]\n",
    "        bar_l = [self.bins[0] + (i+1)*(self.bins[self.nbins-1] - self.bins[0])/(self.nbins) for i in range(len(_to_bar_1))]\n",
    "  \n",
    "        if (self.discrete == True):\n",
    "            bar_width = 1.0\n",
    "            bar_l = self.bar_l\n",
    "        \n",
    "        \n",
    "  \n",
    "    \n",
    "        # positions of the x-axis ticks (center of the bars as bar labels)\n",
    "        tick_pos = [i+(bar_width/2) for i in bar_l] #+ self.bins[0] \n",
    "\n",
    "        # Create a bar plot, in position bar_1\n",
    "        ax1.bar(bar_l,\n",
    "                # using the pre_score data\n",
    "                _to_bar_1,\n",
    "                # set the width\n",
    "                width=bar_width,\n",
    "                # with the label pre score\n",
    "                label='Paga',\n",
    "                # with alpha 0.5\n",
    "                alpha=0.5,\n",
    "                # with color\n",
    "                color='#808000')\n",
    "\n",
    "        # Create a bar plot, in position bar_1\n",
    "        ax1.bar(bar_l,\n",
    "                # using the mid_score data\n",
    "                _to_bar_2,\n",
    "                # set the width\n",
    "                width=bar_width,\n",
    "                # with pre_score on the bottom\n",
    "                bottom=_to_bar_1,\n",
    "                # with the label mid score\n",
    "                label='No paga',\n",
    "                # with alpha 0.5\n",
    "                alpha=0.5,\n",
    "                # with color\n",
    "                color='#4b0082')\n",
    "        \n",
    "\n",
    "        \n",
    "        # Set the label and legends\n",
    "        ax1.set_ylabel(\"Cantidad\")\n",
    "        ax1.set_xlabel(self.name)\n",
    "        ax1.set_xlim(self.xlims)\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Set a buffer around the edge\n",
    "        #plt.xlim([min(tick_pos)-bar_width, max(tick_pos)+bar_width])\n",
    "        \n",
    "class double_graph:\n",
    "    \n",
    "    def __init__(self, index_1, index_2, target_matrix):\n",
    "        self.index = index_1\n",
    "        self.index2 = index_2\n",
    "        rows = len(target_matrix)\n",
    "        self.data = np.zeros(shape=(rows, 3))\n",
    "        \n",
    "        _columns = len(data_matrix[0,:])\n",
    "        self.data[:,0] = data_matrix[:, self.index]\n",
    "        self.data[:,1] = data_matrix[:, _columns - 1]\n",
    "        self.data[:,2] = data_matrix[:, self.index2]\n",
    "        \n",
    "        _N_datos = len(self.data[:,0])\n",
    "        self.convert_data = np.zeros( shape = (_N_datos, 2))\n",
    "    \n",
    "        _Paga = 1;\n",
    "        _NoPaga = 0;\n",
    "\n",
    "        self.feature_1_paid = []\n",
    "        self.feature_2_paid = []\n",
    "        \n",
    "        self.feature_1_nopaid = []\n",
    "        self.feature_2_nopaid = []\n",
    "        \n",
    "        for i in range(_N_datos):\n",
    "            if self.data[i,1] == _Paga:\n",
    "                self.feature_1_paid.append(self.data[i,0]) \n",
    "                self.feature_2_paid.append(self.data[i,2])\n",
    "            else:\n",
    "                self.feature_1_nopaid.append(self.data[i,0])\n",
    "                self.feature_2_nopaid.append(self.data[i,2]) \n",
    "    \n",
    "    def plot(self):\n",
    "        plt.figure()\n",
    "        \n",
    "        p_1_x = self.feature_1_paid \n",
    "        p_1_y = self.feature_2_paid \n",
    "        \n",
    "        p_2_x = self.feature_1_nopaid \n",
    "        p_2_y = self.feature_2_nopaid \n",
    "        \n",
    "        p1, = plt.plot(p_1_x, p_1_y, 'o', color='b', alpha = 0.4)\n",
    "        p2, = plt.plot(p_2_x, p_2_y, 'o', color='y', alpha = 0.4) ##g^\n",
    "\n",
    "        x1 = min(p_1_x)\n",
    "        x2 = min(p_2_x)\n",
    "        x3 = min([x1,x2])\n",
    "        \n",
    "        y1 = min(p_1_y)\n",
    "        y2 = min(p_2_y)\n",
    "        y3 = min([y1, y2])\n",
    "        \n",
    "        x11 = max(p_1_x)\n",
    "        x22 = max(p_2_x)\n",
    "        x33 = max([x11,x22])\n",
    "        \n",
    "        y11 = max(p_1_y)\n",
    "        y22 = max(p_2_y)\n",
    "        y33 = max([y11, y22])\n",
    "        \n",
    "        x_ = x3 - (x33 - x3)*0.10\n",
    "        x_up = x33 + (x33 - x3)*0.10\n",
    "        y_ = y3 - (y33 - y3)*0.10\n",
    "        y_up = y33 + (y33 - y3)*0.10\n",
    "        \n",
    "        print [x_, x_up, y_, y_up]\n",
    "        \n",
    "        plt.axis([x_, x_up, y_, y_up])\n",
    "        plt.xlabel(features_names[self.index-1])\n",
    "        plt.ylabel(features_names[self.index2-1])\n",
    "\n",
    "        \n",
    "        \n",
    "        plt.legend([ p1, p2], [\"Paga\" ,\"No Paga\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICOS HISTOGRAMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_hists = False\n",
    "\n",
    "if plot_hists:\n",
    "\n",
    "    ## EDAD ##\n",
    "    age_hist = Histogram(data_matrix, Y, 3, \"Edad\")\n",
    "    age_hist.set_bins(20,65, 45) ## DE 20 a 60 años, 20 intervalos\n",
    "    age_hist.hist()\n",
    "\n",
    "    ## RENTA ##\n",
    "    rent_hist = Histogram(data_matrix, Y,  2, \"Renta (Pesos)\")\n",
    "    rent_hist.set_bins(40000, 2e6, 20)\n",
    "    rent_hist.hist()\n",
    "\n",
    "    ## GENERO ##\n",
    "    genre_hist = Histogram(data_matrix, Y, 1, \"Genero\")\n",
    "    #rent_hist.set_bins(50000, 1e6, 10)\n",
    "    genre_hist.is_discrete(2)\n",
    "    genre_hist.hist()\n",
    "\n",
    "    ## NIVEL EDUCACIONAL ##\n",
    "    niv_ED_hist = Histogram(data_matrix,Y, 4, \"Nivel Educacional\")\n",
    "    #rent_hist.set_bins(50000, 1e6, 10)\n",
    "    niv_ED_hist.is_discrete(6)\n",
    "    niv_ED_hist.set_xlim([2.5,6.5])\n",
    "    niv_ED_hist.hist()\n",
    "\n",
    "    ## CANTIDAD DE MESES INACTIVO ##\n",
    "    cod_com_hist = Histogram(data_matrix, Y,  16, \"Cantidad de meses inactivo\")\n",
    "    #cod_com_hist.set_bins(0, 3, 3)\n",
    "    cod_com_hist.is_discrete(3)\n",
    "    cod_com_hist.hist()\n",
    "\n",
    "    ## COD_COM ##\n",
    "    cod_com_hist = Histogram(data_matrix, Y,  7, \"Codigo de Comuna\")\n",
    "    cod_com_hist.set_bins(0, 300, 300)\n",
    "    cod_com_hist.hist()\n",
    "\n",
    "    graph = double_graph(4,1, Y)\n",
    "    graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "N_features = (len(data_matrix[0,:]) - 1) # Se resta ID y Label, PAGA o NO PAGA\n",
    "X = data_matrix[:,1:N_features]\n",
    "Y = train_datos.get_target()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.6, random_state = True)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=650, max_depth=None, bootstrap = True, n_jobs = -1)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "importances(clf, X, X_test)\n",
    "\n",
    "\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print \"Score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938100126613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(adaboost, X, Y)\n",
    "print scores.mean()                             \n",
    "\n",
    "adaboost.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  173.250s\n",
      "0.867480383609\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, train_size=0.5, random_state = True)\n",
    "\n",
    "clf = svm.SVC(degree=3)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "score = metrics.accuracy_score(Y_test, pred)\n",
    "print score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
